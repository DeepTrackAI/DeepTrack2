{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from loader import *\n",
    "from models import *\n",
    "from utils import *\n",
    "from plotting import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "moving_plankton = moving_spherical_plankton(im_size_height=512, \n",
    "                                            im_size_width=640, \n",
    "                                            radius=0.4e-6, \n",
    "                                            label=1, \n",
    "                                            diffusion_constant_coeff=1.3)\n",
    "\n",
    "stationary_plankton = stationary_spherical_plankton(im_size_height=512, \n",
    "                                                    im_size_width=640, \n",
    "                                                    radius=0.2e-6, \n",
    "                                                    label=0)\n",
    "\n",
    "sequential_moving_plankton = Sequential(moving_plankton, position=get_position_moving_plankton)\n",
    "sequential_stationary_plankton = Sequential(stationary_plankton, position=get_position_stationary_plankton)\n",
    "\n",
    "microscope = plankton_brightfield(im_size_height=512, \n",
    "                                  im_size_width=640, \n",
    "                                  gradient_amp=0.1)\n",
    "\n",
    "no_of_moving_planktons, no_of_stationary_planktons = 80, 200\n",
    "\n",
    "sample = create_sample(sequential_moving_plankton, no_of_moving_planktons, \n",
    "                       sequential_stationary_plankton, no_of_stationary_planktons) \n",
    "\n",
    "noise_amp = 0.1\n",
    "norm_min, norm_max= 0, 1\n",
    "sequence = create_sequence(noise_amp, sample, microscope, norm_min, norm_max)\n",
    "\n",
    "sequence_length = 3\n",
    "imaged_particle_sequence = Sequence(sequence, sequence_length=sequence_length)\n",
    "\n",
    "imaged_particle_sequence.plot(cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "label = get_target_sequence(imaged_particle_sequence.resolve())\n",
    "label_function = get_target_sequence\n",
    "plot_label(label_function, imaged_particle_sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_function = create_custom_batch_function(imaged_particle_sequence, \n",
    "                                              outputs=[0,1,2], \n",
    "                                              function_img=[Normalize_image],\n",
    "                                              function_diff=[Normalize_image])\n",
    "\n",
    "\n",
    "train_images = batch_function(imaged_particle_sequence.resolve())\n",
    "\n",
    "plot_batch(train_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deeptrack.generators import ContinuousGenerator\n",
    "generator = ContinuousGenerator(\n",
    "    imaged_particle_sequence,\n",
    "    get_target_sequence,\n",
    "    batch_function,\n",
    "    batch_size=8,\n",
    "    min_data_size=80,\n",
    "    max_data_size=512\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = generate_unet(im_size_height=512, im_size_width=640, no_of_inputs=3, number_of_outputs=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = train_model(model, generator, patience=20, epochs=50, steps_per_epoch=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# change outputs\n",
    "im_stack = get_image_stack(outputs=[0, 1, 2], \n",
    "                           folder_path = 'E:\\Documents\\Anaconda\\Jupyterkod\\Exjobb\\Egen kod\\Exjobb\\From erik\\\\alexandrium2', \n",
    "                           frame_im0 = 39, \n",
    "                           im_size_width = 640, \n",
    "                           im_size_height = 512,\n",
    "                           function_img=[Normalize_image], \n",
    "                           function_diff=[Normalize_image])\n",
    "\n",
    "# plot_im_stack(im_stack)\n",
    "# plot_prediction(model=model, im_stack=im_stack)\n",
    "plt.imshow(model.predict(im_stack)[0,:,:,1], cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.max(model.predict(im_stack)[0,:,:,1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "positions = extract_positions(\n",
    "    no_of_frames = 10, \n",
    "    outputs=[0,1,2], \n",
    "    folder_path = 'E:\\Documents\\Anaconda\\Jupyterkod\\Exjobb\\Egen kod\\Exjobb\\From erik\\\\alexandrium2', \n",
    "    frame_im0 = 39, \n",
    "    im_size_width = 640, \n",
    "    im_size_height = 512,\n",
    "    model = model, \n",
    "    layer = 2, \n",
    "    value_threshold=0.4,\n",
    "    function_img=[Normalize_image], \n",
    "    function_diff=[Normalize_image])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_plankton = assign_positions_to_planktons(positions, max_dist=25, threshold = 11, extrapolate=True)\n",
    "list_of_plankton = Interpolate_gaps_in_plankton_positions(list_of_plankton=list_of_plankton)\n",
    "list_of_plankton = Trim_list_from_stationary_planktons(list_of_plankton=list_of_plankton, min_distance=25)\n",
    "\n",
    "plankton_track, plankton_dont_track = split_plankton(percentage_threshold=0, list_of_plankton=list_of_plankton)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot_and_save_track(no_of_frames = len(list_of_plankton[list(list_of_plankton.keys())[0]].positions),\n",
    "                    plankton_track = plankton_track,\n",
    "                    plankton_dont_track = plankton_dont_track,\n",
    "                    folder_path = 'E:\\Documents\\Anaconda\\Jupyterkod\\Exjobb\\Egen kod\\Exjobb\\From erik\\\\alexandrium2',\n",
    "                    frame_im0 = 40,\n",
    "                    save_images=False,\n",
    "                    show_plankton_track = True,\n",
    "                    show_plankton_dont_track = True,\n",
    "                    show_numbers_track = True,\n",
    "                    show_numbers_dont_track = True,\n",
    "                    show_numbers_specific_plankton = False,\n",
    "                    show_specific_plankton = False,\n",
    "                    specific_plankton = None,\n",
    "                    color_plankton_track = 'b',\n",
    "                    color_plankton_dont_track = 'r',\n",
    "                    color_specific_plankton = 'w',\n",
    "                    save_path = 'E:\\\\Documents\\\\Anaconda\\\\Jupyterkod\\\\Exjobb\\\\Egen kod\\\\Exjobb\\\\New imulations\\\\Raw_output',\n",
    "                    frame_name = 'track',\n",
    "                    file_type = '.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_plankton"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "csv_columns = []\n",
    "plankton_dict = list_of_plankton\n",
    "for key in plankton_dict:\n",
    "    csv_columns.append([key + ' x-position', key + ' y-position'])\n",
    "\n",
    "dict_data = [\n",
    "{'No': 1, 'Name': 'Alex', 'Country': 'India'},\n",
    "{'No': 2, 'Name': 'Ben', 'Country': 'USA'},\n",
    "{'No': 3, 'Name': 'Shri Ram', 'Country': 'India'},\n",
    "{'No': 4, 'Name': 'Smith', 'Country': 'USA'},\n",
    "{'No': 5, 'Name': 'Yuva Raj', 'Country': 'India'},\n",
    "]\n",
    "csv_file = \"plankton_pos.csv\"\n",
    "try:\n",
    "    with open(csv_file, 'w') as csvfile:\n",
    "        writer = csv.DictWriter(csvfile, fieldnames=csv_columns)\n",
    "        writer.writeheader()\n",
    "        for data in dict_data:\n",
    "            writer.writerow(data)\n",
    "except IOError:\n",
    "    print(\"I/O error\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_data = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_columns = []\n",
    "for key in list_of_plankton:\n",
    "    csv_columns.append([key + ' x-position', key + ' y-position'])\n",
    "\n",
    "csv_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtype(list_of_plankton['plankton4'].positions,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.shape(list_of_plankton[list(list_of_plankton.keys())[0]].positions.astype('float64'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shape_position = np.shape(list_of_plankton[list(list_of_plankton.keys())[0]].positions.astype('float64'))\n",
    "\n",
    "positions_array = np.zeros((shape_position[0], len(list_of_plankton)*2))\n",
    "\n",
    "header = []\n",
    "\n",
    "for i, key in enumerate(list_of_plankton):\n",
    "    positions_array[:,2*i:2*(i+1)] = list_of_plankton[key].positions.astype('float64')\n",
    "    header.append(key + ' x-position')\n",
    "    header.append(key + ' y-position')\n",
    "\n",
    "positions_array\n",
    "header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[None]*5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install pandas\n",
    "# !pip install openpyxl\n",
    "# import pandas as pd\n",
    "\n",
    "## convert your array into a dataframe\n",
    "\n",
    "\n",
    "shape_position = np.shape(list_of_plankton[list(list_of_plankton.keys())[0]].positions.astype('float64'))\n",
    "\n",
    "positions_array = np.zeros((shape_position[0], len(list_of_plankton)*2))\n",
    "\n",
    "header = [None]*len(list_of_plankton)*2\n",
    "\n",
    "for i, key in enumerate(list_of_plankton):\n",
    "    positions_array[:,2*i:2*(i+1)] = list_of_plankton[key].positions.astype('float64')\n",
    "    header[2*i]=key + ' x-position'\n",
    "    header[2*i+1]=key + ' y-position'\n",
    "\n",
    "\n",
    "\n",
    "df = pd.DataFrame (positions_array)\n",
    "\n",
    "## save to xlsx file\n",
    "\n",
    "filepath = 'my_xlsx_file.xlsx'\n",
    "\n",
    "df.to_xlsx(filepath, header=header)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shape_position = np.shape(list_of_plankton[list(list_of_plankton.keys())[0]].positions.astype('float64'))\n",
    "\n",
    "positions_array = np.zeros((shape_position[0], len(list_of_plankton)*2))\n",
    "\n",
    "header = [None]*len(list_of_plankton)*2\n",
    "\n",
    "for i, key in enumerate(list_of_plankton):\n",
    "    positions_array[:,2*i:2*(i+1)] = list_of_plankton[key].positions.astype('float64')\n",
    "    header[2*i]=key + ' x-position'\n",
    "    header[2*i+1]=key + ' y-position'\n",
    "\n",
    "\n",
    "\n",
    "df = pd.DataFrame (positions_array)\n",
    "\n",
    "## save to csv file\n",
    "\n",
    "filepath = 'my_csv_file.csv'\n",
    "\n",
    "df.to_csv(filepath, header=header)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
