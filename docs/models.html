
<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta charset="utf-8" />
    <title>models &#8212; DeepTrack 2.0 documentation</title>
    
  <link href="_static/css/theme.css" rel="stylesheet" />
  <link href="_static/css/index.f6b7ca918bee2f46fd9abac01cfb07d5.css" rel="stylesheet" />

    
  <link rel="stylesheet"
    href="_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      

    
    <link rel="stylesheet" href="_static/basic.css" type="text/css" />
    <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
    
  <link rel="preload" as="script" href="_static/js/index.1e043a052b0af929e4d8.js">

    <script type="text/javascript" id="documentation_options" data-url_root="./" src="_static/documentation_options.js"></script>
    <script type="text/javascript" src="_static/jquery.js"></script>
    <script type="text/javascript" src="_static/underscore.js"></script>
    <script type="text/javascript" src="_static/doctools.js"></script>
    <script type="text/javascript" src="_static/language_data.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="noises" href="noises.html" />
    <link rel="prev" title="math" href="math.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="en" />
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    
    <nav class="navbar navbar-light navbar-expand-lg bg-light fixed-top bd-navbar" id="navbar-main"><div class="container-xl">


    
    <a class="navbar-brand" href="index.html">
      <p class="title">DeepTrack</p>
    </a>
    

    <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbar-menu" aria-controls="navbar-menu" aria-expanded="false" aria-label="Toggle navigation">
        <span class="navbar-toggler-icon"></span>
    </button>

    
    <div id="navbar-menu" class="col-lg-9 collapse navbar-collapse">
      <ul id="navbar-main-elements" class="navbar-nav mr-auto">
        <li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="installation.html">
  Getting started
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="tutorials.html">
  Tutorials and notebooks
 </a>
</li>

<li class="toctree-l1 current active nav-item">
 <a class="reference internal nav-link" href="deeptrack.html">
  Documentation
 </a>
</li>

        
      </ul>

      <ul id="navbar-icon-links" class="navbar-nav" aria-label="Icon Links">
      </ul>
    </div>
</div>
    </nav>
    

    <div class="container-xl">
      <div class="row">
          
            
            <!-- Only show if we have sidebars configured, else just a small margin  -->
            <div class="col-12 col-md-3 bd-sidebar"><form class="bd-search d-flex align-items-center" action="search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search the docs ..." aria-label="Search the docs ..." autocomplete="off" >
</form>
<nav class="bd-links" id="bd-docs-nav" aria-label="Main navigation">
  <div class="bd-toc-item active">
    <ul class="current nav bd-sidenav">
 <li class="toctree-l2">
  <a class="reference internal" href="backend.html">
   backend
  </a>
 </li>
 <li class="toctree-l2">
  <a class="reference internal" href="aberrations.html">
   aberrations
  </a>
 </li>
 <li class="toctree-l2">
  <a class="reference internal" href="augmentations.html">
   augmentations
  </a>
 </li>
 <li class="toctree-l2">
  <a class="reference internal" href="elementwise.html">
   elementwise
  </a>
 </li>
 <li class="toctree-l2">
  <a class="reference internal" href="features.html">
   features
  </a>
 </li>
 <li class="toctree-l2">
  <a class="reference internal" href="generators.html">
   generators
  </a>
 </li>
 <li class="toctree-l2">
  <a class="reference internal" href="image.html">
   image
  </a>
 </li>
 <li class="toctree-l2">
  <a class="reference internal" href="layers.html">
   layers
  </a>
 </li>
 <li class="toctree-l2">
  <a class="reference internal" href="losses.html">
   losses
  </a>
 </li>
 <li class="toctree-l2">
  <a class="reference internal" href="math.html">
   math
  </a>
 </li>
 <li class="toctree-l2 current active">
  <a class="current reference internal" href="#">
   models
  </a>
 </li>
 <li class="toctree-l2">
  <a class="reference internal" href="noises.html">
   noises
  </a>
 </li>
 <li class="toctree-l2">
  <a class="reference internal" href="optics.html">
   optics
  </a>
 </li>
 <li class="toctree-l2">
  <a class="reference internal" href="properties.html">
   properties
  </a>
 </li>
 <li class="toctree-l2">
  <a class="reference internal" href="scatterers.html">
   scatterers
  </a>
 </li>
 <li class="toctree-l2">
  <a class="reference internal" href="sequences.html">
   sequences
  </a>
 </li>
 <li class="toctree-l2">
  <a class="reference internal" href="statistics.html">
   statistics
  </a>
 </li>
 <li class="toctree-l2">
  <a class="reference internal" href="test.html">
   test
  </a>
 </li>
 <li class="toctree-l2">
  <a class="reference internal" href="types.html">
   types
  </a>
 </li>
 <li class="toctree-l2">
  <a class="reference internal" href="utils.html">
   utils
  </a>
 </li>
</ul>
  </div>
</nav>
            </div>
            
          

          
          <div class="d-none d-xl-block col-xl-2 bd-toc">
              
<div class="tocsection onthispage pt-5 pb-3">
    <i class="fas fa-list"></i> On this page
</div>

<nav id="bd-toc-nav">
    <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#autotracking">
   autotracking
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#dense">
   dense
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#module-classes">
     Module classes
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#fullyconnected">
       FullyConnected
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#equivariances">
   equivariances
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id1">
     Module classes
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#equivariance">
       Equivariance
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#logscaleequivariance">
       LogScaleEquivariance
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#rotational2dequivariance">
       Rotational2DEquivariance
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#scaleequivariance">
       ScaleEquivariance
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#translationalequivariance">
       TranslationalEquivariance
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#generators">
   generators
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id2">
     Module classes
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#autotrackgenerator">
       AutoTrackGenerator
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#id3">
   models
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id4">
     Module classes
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#automultitracker">
       AutoMultiTracker
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#autotracker">
       AutoTracker
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#autotrackerbasemodel">
       AutoTrackerBaseModel
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#recurrent">
   recurrent
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id9">
     Module classes
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#rnn">
       RNN
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id10">
       rnn
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#utils">
   utils
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id11">
     Module classes
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#kerasmodel">
       KerasModel
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#model">
       Model
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#module-functions">
     Module functions
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#loadmodel">
       LoadModel
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#as-kerasmodel">
       as_KerasModel
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#compile">
       compile
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#load-model">
       load_model
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#register-config">
       register_config
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#with-citation">
       with_citation
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
</ul>

</nav>


              
          </div>
          

          
          
            
          
          <main class="col-12 col-md-9 col-xl-7 py-md-5 pl-md-5 pr-md-4 bd-content" role="main">
              
              <div>
                
  <div class="section" id="module-deeptrack.models">
<span id="models"></span><h1>models<a class="headerlink" href="#module-deeptrack.models" title="Permalink to this headline">¶</a></h1>
<div class="section" id="autotracking">
<h2>autotracking<a class="headerlink" href="#autotracking" title="Permalink to this headline">¶</a></h2>
</div>
<div class="section" id="dense">
<h2>dense<a class="headerlink" href="#dense" title="Permalink to this headline">¶</a></h2>
<div class="section" id="module-classes">
<h3>Module classes<a class="headerlink" href="#module-classes" title="Permalink to this headline">¶</a></h3>
<div class="section" id="fullyconnected">
<h4>FullyConnected<a class="headerlink" href="#fullyconnected" title="Permalink to this headline">¶</a></h4>
<dl class="class">
<dt id="deeptrack.models.FullyConnected">
<em class="property">class </em><code class="sig-prename descclassname">deeptrack.models.</code><code class="sig-name descname">FullyConnected</code><span class="sig-paren">(</span><em class="sig-param">input_shape</em>, <em class="sig-param">dense_layers_dimensions=(32</em>, <em class="sig-param">32)</em>, <em class="sig-param">dropout=()</em>, <em class="sig-param">flatten_input=True</em>, <em class="sig-param">number_of_outputs=3</em>, <em class="sig-param">output_activation=None</em>, <em class="sig-param">dense_block='dense'</em>, <em class="sig-param">**kwargs</em><span class="sig-paren">)</span><a class="headerlink" href="#deeptrack.models.FullyConnected" title="Permalink to this definition">¶</a></dt>
<dd><p class="rubric">Methods</p>
<table class="longtable table autosummary">
<colgroup>
<col style="width: 10%" />
<col style="width: 90%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">__call__</span></code>(*args, **kwargs)</p></td>
<td><p>Call self as a function.</p></td>
</tr>
<tr class="row-even"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">action</span></code>([replicate_index])</p></td>
<td><p>Creates the image.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">data_generator</span></code></p></td>
<td><p>alias of <a class="reference internal" href="generators.html#deeptrack.generators.ContinuousGenerator" title="deeptrack.generators.ContinuousGenerator"><code class="xref py py-class docutils literal notranslate"><span class="pre">deeptrack.generators.ContinuousGenerator</span></code></a></p></td>
</tr>
<tr class="row-even"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">export</span></code>(path, minimum_size[, preprocessing, …])</p></td>
<td><p>Export model unto the BioImage Model Zoo format for use with Fiji and ImageJ.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">fit</span></code>([x, y, batch_size, epochs, verbose, …])</p></td>
<td><p>Trains the model for a fixed number of epochs (iterations on a dataset).</p></td>
</tr>
<tr class="row-even"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">plot</span></code>([input_image, resolve_kwargs, interval])</p></td>
<td><p>Visualizes the output of the feature.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">resolve</span></code>([image_list, replicate_index])</p></td>
<td><p>Call self as a function.</p></td>
</tr>
<tr class="row-even"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">sample</span></code>(**kwargs)</p></td>
<td><p>Returns the feature</p></td>
</tr>
</tbody>
</table>
<table class="table">
<colgroup>
<col style="width: 71%" />
<col style="width: 29%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><strong>add_child</strong></p></td>
<td></td>
</tr>
<tr class="row-even"><td><p><strong>add_dependency</strong></p></td>
<td></td>
</tr>
<tr class="row-odd"><td><p><strong>add_feature</strong></p></td>
<td></td>
</tr>
<tr class="row-even"><td><p><strong>add_preprocessing</strong></p></td>
<td></td>
</tr>
<tr class="row-odd"><td><p><strong>bind_arguments</strong></p></td>
<td></td>
</tr>
<tr class="row-even"><td><p><strong>current_value</strong></p></td>
<td></td>
</tr>
<tr class="row-odd"><td><p><strong>get_citations</strong></p></td>
<td></td>
</tr>
<tr class="row-even"><td><p><strong>invalidate</strong></p></td>
<td></td>
</tr>
<tr class="row-odd"><td><p><strong>is_valid</strong></p></td>
<td></td>
</tr>
<tr class="row-even"><td><p><strong>previous</strong></p></td>
<td></td>
</tr>
<tr class="row-odd"><td><p><strong>recurse_children</strong></p></td>
<td></td>
</tr>
<tr class="row-even"><td><p><strong>recurse_dependencies</strong></p></td>
<td></td>
</tr>
<tr class="row-odd"><td><p><strong>seed</strong></p></td>
<td></td>
</tr>
<tr class="row-even"><td><p><strong>set_value</strong></p></td>
<td></td>
</tr>
<tr class="row-odd"><td><p><strong>store</strong></p></td>
<td></td>
</tr>
<tr class="row-even"><td><p><strong>update</strong></p></td>
<td></td>
</tr>
<tr class="row-odd"><td><p><strong>valid_index</strong></p></td>
<td></td>
</tr>
<tr class="row-even"><td><p><strong>validate</strong></p></td>
<td></td>
</tr>
</tbody>
</table>
</dd></dl>

</div>
</div>
</div>
<div class="section" id="equivariances">
<h2>equivariances<a class="headerlink" href="#equivariances" title="Permalink to this headline">¶</a></h2>
<div class="section" id="id1">
<h3>Module classes<a class="headerlink" href="#id1" title="Permalink to this headline">¶</a></h3>
<div class="section" id="equivariance">
<h4>Equivariance<a class="headerlink" href="#equivariance" title="Permalink to this headline">¶</a></h4>
<dl class="class">
<dt id="deeptrack.models.Equivariance">
<em class="property">class </em><code class="sig-prename descclassname">deeptrack.models.</code><code class="sig-name descname">Equivariance</code><span class="sig-paren">(</span><em class="sig-param">mul</em>, <em class="sig-param">add</em>, <em class="sig-param">indexes=slice(None</em>, <em class="sig-param">None</em>, <em class="sig-param">1)</em>, <em class="sig-param">**kwargs</em><span class="sig-paren">)</span><a class="headerlink" href="#deeptrack.models.Equivariance" title="Permalink to this definition">¶</a></dt>
<dd><p>Defines equivariance between action and prediction.</p>
<p>Should define both a multiplicative equivariance (1, if invariant) and a additive equivariance (0, if invariant)</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>mul</strong><span class="classifier">float, array-like</span></dt><dd><p>Multiplicative equivariance</p>
</dd>
<dt><strong>add</strong><span class="classifier">float, array-like</span></dt><dd><p>Additive equivariance</p>
</dd>
<dt><strong>indexes</strong><span class="classifier">optional, int or slice</span></dt><dd><p>Index of related predicted value(s)</p>
</dd>
</dl>
</dd>
</dl>
<p class="rubric">Methods</p>
<table class="longtable table autosummary">
<colgroup>
<col style="width: 10%" />
<col style="width: 90%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">__call__</span></code>([image_list, replicate_index])</p></td>
<td><p>Call self as a function.</p></td>
</tr>
<tr class="row-even"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">action</span></code>([replicate_index])</p></td>
<td><p>Creates the image.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">plot</span></code>([input_image, resolve_kwargs, interval])</p></td>
<td><p>Visualizes the output of the feature.</p></td>
</tr>
<tr class="row-even"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">resolve</span></code>([image_list, replicate_index])</p></td>
<td><p>Call self as a function.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">sample</span></code>(**kwargs)</p></td>
<td><p>Returns the feature</p></td>
</tr>
</tbody>
</table>
<table class="table">
<colgroup>
<col style="width: 71%" />
<col style="width: 29%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><strong>add_child</strong></p></td>
<td></td>
</tr>
<tr class="row-even"><td><p><strong>add_dependency</strong></p></td>
<td></td>
</tr>
<tr class="row-odd"><td><p><strong>add_feature</strong></p></td>
<td></td>
</tr>
<tr class="row-even"><td><p><strong>bind_arguments</strong></p></td>
<td></td>
</tr>
<tr class="row-odd"><td><p><strong>current_value</strong></p></td>
<td></td>
</tr>
<tr class="row-even"><td><p><strong>get_citations</strong></p></td>
<td></td>
</tr>
<tr class="row-odd"><td><p><strong>invalidate</strong></p></td>
<td></td>
</tr>
<tr class="row-even"><td><p><strong>is_valid</strong></p></td>
<td></td>
</tr>
<tr class="row-odd"><td><p><strong>previous</strong></p></td>
<td></td>
</tr>
<tr class="row-even"><td><p><strong>recurse_children</strong></p></td>
<td></td>
</tr>
<tr class="row-odd"><td><p><strong>recurse_dependencies</strong></p></td>
<td></td>
</tr>
<tr class="row-even"><td><p><strong>seed</strong></p></td>
<td></td>
</tr>
<tr class="row-odd"><td><p><strong>set_value</strong></p></td>
<td></td>
</tr>
<tr class="row-even"><td><p><strong>store</strong></p></td>
<td></td>
</tr>
<tr class="row-odd"><td><p><strong>update</strong></p></td>
<td></td>
</tr>
<tr class="row-even"><td><p><strong>valid_index</strong></p></td>
<td></td>
</tr>
<tr class="row-odd"><td><p><strong>validate</strong></p></td>
<td></td>
</tr>
</tbody>
</table>
</dd></dl>

</div>
<div class="section" id="logscaleequivariance">
<h4>LogScaleEquivariance<a class="headerlink" href="#logscaleequivariance" title="Permalink to this headline">¶</a></h4>
<dl class="class">
<dt id="deeptrack.models.LogScaleEquivariance">
<em class="property">class </em><code class="sig-prename descclassname">deeptrack.models.</code><code class="sig-name descname">LogScaleEquivariance</code><span class="sig-paren">(</span><em class="sig-param">scale</em>, <em class="sig-param">indexes=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deeptrack.models.LogScaleEquivariance" title="Permalink to this definition">¶</a></dt>
<dd><p>Defines scale-like equivariance between action and prediction, for use with dt.Affine</p>
<p>Converts the scaling to log scale, for an additive equivariance.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>scale</strong><span class="classifier">float, array-like</span></dt><dd><p>Should be exactly <cite>affine.scale</cite></p>
</dd>
</dl>
</dd>
</dl>
<p class="rubric">Methods</p>
<table class="longtable table autosummary">
<colgroup>
<col style="width: 10%" />
<col style="width: 90%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">__call__</span></code>([image_list, replicate_index])</p></td>
<td><p>Call self as a function.</p></td>
</tr>
<tr class="row-even"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">action</span></code>([replicate_index])</p></td>
<td><p>Creates the image.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">plot</span></code>([input_image, resolve_kwargs, interval])</p></td>
<td><p>Visualizes the output of the feature.</p></td>
</tr>
<tr class="row-even"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">resolve</span></code>([image_list, replicate_index])</p></td>
<td><p>Call self as a function.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">sample</span></code>(**kwargs)</p></td>
<td><p>Returns the feature</p></td>
</tr>
</tbody>
</table>
<table class="table">
<colgroup>
<col style="width: 71%" />
<col style="width: 29%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><strong>add_child</strong></p></td>
<td></td>
</tr>
<tr class="row-even"><td><p><strong>add_dependency</strong></p></td>
<td></td>
</tr>
<tr class="row-odd"><td><p><strong>add_feature</strong></p></td>
<td></td>
</tr>
<tr class="row-even"><td><p><strong>bind_arguments</strong></p></td>
<td></td>
</tr>
<tr class="row-odd"><td><p><strong>current_value</strong></p></td>
<td></td>
</tr>
<tr class="row-even"><td><p><strong>get_add</strong></p></td>
<td></td>
</tr>
<tr class="row-odd"><td><p><strong>get_citations</strong></p></td>
<td></td>
</tr>
<tr class="row-even"><td><p><strong>get_indexes</strong></p></td>
<td></td>
</tr>
<tr class="row-odd"><td><p><strong>get_mul</strong></p></td>
<td></td>
</tr>
<tr class="row-even"><td><p><strong>invalidate</strong></p></td>
<td></td>
</tr>
<tr class="row-odd"><td><p><strong>is_valid</strong></p></td>
<td></td>
</tr>
<tr class="row-even"><td><p><strong>previous</strong></p></td>
<td></td>
</tr>
<tr class="row-odd"><td><p><strong>recurse_children</strong></p></td>
<td></td>
</tr>
<tr class="row-even"><td><p><strong>recurse_dependencies</strong></p></td>
<td></td>
</tr>
<tr class="row-odd"><td><p><strong>seed</strong></p></td>
<td></td>
</tr>
<tr class="row-even"><td><p><strong>set_value</strong></p></td>
<td></td>
</tr>
<tr class="row-odd"><td><p><strong>store</strong></p></td>
<td></td>
</tr>
<tr class="row-even"><td><p><strong>update</strong></p></td>
<td></td>
</tr>
<tr class="row-odd"><td><p><strong>valid_index</strong></p></td>
<td></td>
</tr>
<tr class="row-even"><td><p><strong>validate</strong></p></td>
<td></td>
</tr>
</tbody>
</table>
</dd></dl>

</div>
<div class="section" id="rotational2dequivariance">
<h4>Rotational2DEquivariance<a class="headerlink" href="#rotational2dequivariance" title="Permalink to this headline">¶</a></h4>
<dl class="class">
<dt id="deeptrack.models.Rotational2DEquivariance">
<em class="property">class </em><code class="sig-prename descclassname">deeptrack.models.</code><code class="sig-name descname">Rotational2DEquivariance</code><span class="sig-paren">(</span><em class="sig-param">rotate</em>, <em class="sig-param">indexes=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deeptrack.models.Rotational2DEquivariance" title="Permalink to this definition">¶</a></dt>
<dd><p>Defines rotation-like equivariance between action and prediction, for use with dt.Affine</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>rotate</strong><span class="classifier">float, array-like</span></dt><dd><p>Should be exactly <cite>affine.rotate</cite></p>
</dd>
</dl>
</dd>
</dl>
<p class="rubric">Methods</p>
<table class="longtable table autosummary">
<colgroup>
<col style="width: 10%" />
<col style="width: 90%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">__call__</span></code>([image_list, replicate_index])</p></td>
<td><p>Call self as a function.</p></td>
</tr>
<tr class="row-even"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">action</span></code>([replicate_index])</p></td>
<td><p>Creates the image.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">plot</span></code>([input_image, resolve_kwargs, interval])</p></td>
<td><p>Visualizes the output of the feature.</p></td>
</tr>
<tr class="row-even"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">resolve</span></code>([image_list, replicate_index])</p></td>
<td><p>Call self as a function.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">sample</span></code>(**kwargs)</p></td>
<td><p>Returns the feature</p></td>
</tr>
</tbody>
</table>
<table class="table">
<colgroup>
<col style="width: 71%" />
<col style="width: 29%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><strong>add_child</strong></p></td>
<td></td>
</tr>
<tr class="row-even"><td><p><strong>add_dependency</strong></p></td>
<td></td>
</tr>
<tr class="row-odd"><td><p><strong>add_feature</strong></p></td>
<td></td>
</tr>
<tr class="row-even"><td><p><strong>bind_arguments</strong></p></td>
<td></td>
</tr>
<tr class="row-odd"><td><p><strong>current_value</strong></p></td>
<td></td>
</tr>
<tr class="row-even"><td><p><strong>get_add</strong></p></td>
<td></td>
</tr>
<tr class="row-odd"><td><p><strong>get_citations</strong></p></td>
<td></td>
</tr>
<tr class="row-even"><td><p><strong>get_indexes</strong></p></td>
<td></td>
</tr>
<tr class="row-odd"><td><p><strong>get_mul</strong></p></td>
<td></td>
</tr>
<tr class="row-even"><td><p><strong>invalidate</strong></p></td>
<td></td>
</tr>
<tr class="row-odd"><td><p><strong>is_valid</strong></p></td>
<td></td>
</tr>
<tr class="row-even"><td><p><strong>previous</strong></p></td>
<td></td>
</tr>
<tr class="row-odd"><td><p><strong>recurse_children</strong></p></td>
<td></td>
</tr>
<tr class="row-even"><td><p><strong>recurse_dependencies</strong></p></td>
<td></td>
</tr>
<tr class="row-odd"><td><p><strong>seed</strong></p></td>
<td></td>
</tr>
<tr class="row-even"><td><p><strong>set_value</strong></p></td>
<td></td>
</tr>
<tr class="row-odd"><td><p><strong>store</strong></p></td>
<td></td>
</tr>
<tr class="row-even"><td><p><strong>update</strong></p></td>
<td></td>
</tr>
<tr class="row-odd"><td><p><strong>valid_index</strong></p></td>
<td></td>
</tr>
<tr class="row-even"><td><p><strong>validate</strong></p></td>
<td></td>
</tr>
</tbody>
</table>
</dd></dl>

</div>
<div class="section" id="scaleequivariance">
<h4>ScaleEquivariance<a class="headerlink" href="#scaleequivariance" title="Permalink to this headline">¶</a></h4>
<dl class="class">
<dt id="deeptrack.models.ScaleEquivariance">
<em class="property">class </em><code class="sig-prename descclassname">deeptrack.models.</code><code class="sig-name descname">ScaleEquivariance</code><span class="sig-paren">(</span><em class="sig-param">scale</em>, <em class="sig-param">indexes=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deeptrack.models.ScaleEquivariance" title="Permalink to this definition">¶</a></dt>
<dd><p>Defines scale-like equivariance between action and prediction, for use with dt.Affine</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>scale</strong><span class="classifier">float, array-like</span></dt><dd><p>Should be exactly <cite>affine.scale</cite></p>
</dd>
</dl>
</dd>
</dl>
<p class="rubric">Methods</p>
<table class="longtable table autosummary">
<colgroup>
<col style="width: 10%" />
<col style="width: 90%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">__call__</span></code>([image_list, replicate_index])</p></td>
<td><p>Call self as a function.</p></td>
</tr>
<tr class="row-even"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">action</span></code>([replicate_index])</p></td>
<td><p>Creates the image.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">plot</span></code>([input_image, resolve_kwargs, interval])</p></td>
<td><p>Visualizes the output of the feature.</p></td>
</tr>
<tr class="row-even"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">resolve</span></code>([image_list, replicate_index])</p></td>
<td><p>Call self as a function.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">sample</span></code>(**kwargs)</p></td>
<td><p>Returns the feature</p></td>
</tr>
</tbody>
</table>
<table class="table">
<colgroup>
<col style="width: 71%" />
<col style="width: 29%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><strong>add_child</strong></p></td>
<td></td>
</tr>
<tr class="row-even"><td><p><strong>add_dependency</strong></p></td>
<td></td>
</tr>
<tr class="row-odd"><td><p><strong>add_feature</strong></p></td>
<td></td>
</tr>
<tr class="row-even"><td><p><strong>bind_arguments</strong></p></td>
<td></td>
</tr>
<tr class="row-odd"><td><p><strong>current_value</strong></p></td>
<td></td>
</tr>
<tr class="row-even"><td><p><strong>get_add</strong></p></td>
<td></td>
</tr>
<tr class="row-odd"><td><p><strong>get_citations</strong></p></td>
<td></td>
</tr>
<tr class="row-even"><td><p><strong>get_indexes</strong></p></td>
<td></td>
</tr>
<tr class="row-odd"><td><p><strong>get_mul</strong></p></td>
<td></td>
</tr>
<tr class="row-even"><td><p><strong>invalidate</strong></p></td>
<td></td>
</tr>
<tr class="row-odd"><td><p><strong>is_valid</strong></p></td>
<td></td>
</tr>
<tr class="row-even"><td><p><strong>previous</strong></p></td>
<td></td>
</tr>
<tr class="row-odd"><td><p><strong>recurse_children</strong></p></td>
<td></td>
</tr>
<tr class="row-even"><td><p><strong>recurse_dependencies</strong></p></td>
<td></td>
</tr>
<tr class="row-odd"><td><p><strong>seed</strong></p></td>
<td></td>
</tr>
<tr class="row-even"><td><p><strong>set_value</strong></p></td>
<td></td>
</tr>
<tr class="row-odd"><td><p><strong>store</strong></p></td>
<td></td>
</tr>
<tr class="row-even"><td><p><strong>update</strong></p></td>
<td></td>
</tr>
<tr class="row-odd"><td><p><strong>valid_index</strong></p></td>
<td></td>
</tr>
<tr class="row-even"><td><p><strong>validate</strong></p></td>
<td></td>
</tr>
</tbody>
</table>
</dd></dl>

</div>
<div class="section" id="translationalequivariance">
<h4>TranslationalEquivariance<a class="headerlink" href="#translationalequivariance" title="Permalink to this headline">¶</a></h4>
<dl class="class">
<dt id="deeptrack.models.TranslationalEquivariance">
<em class="property">class </em><code class="sig-prename descclassname">deeptrack.models.</code><code class="sig-name descname">TranslationalEquivariance</code><span class="sig-paren">(</span><em class="sig-param">translation</em>, <em class="sig-param">indexes=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deeptrack.models.TranslationalEquivariance" title="Permalink to this definition">¶</a></dt>
<dd><p>Defines translation-like equivariance between action and prediction, for use with dt.Affine</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>translate</strong><span class="classifier">float, array-like</span></dt><dd><p>Should be exactly <cite>affine.translate</cite></p>
</dd>
</dl>
</dd>
</dl>
<p class="rubric">Methods</p>
<table class="longtable table autosummary">
<colgroup>
<col style="width: 10%" />
<col style="width: 90%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">__call__</span></code>([image_list, replicate_index])</p></td>
<td><p>Call self as a function.</p></td>
</tr>
<tr class="row-even"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">action</span></code>([replicate_index])</p></td>
<td><p>Creates the image.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">plot</span></code>([input_image, resolve_kwargs, interval])</p></td>
<td><p>Visualizes the output of the feature.</p></td>
</tr>
<tr class="row-even"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">resolve</span></code>([image_list, replicate_index])</p></td>
<td><p>Call self as a function.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">sample</span></code>(**kwargs)</p></td>
<td><p>Returns the feature</p></td>
</tr>
</tbody>
</table>
<table class="table">
<colgroup>
<col style="width: 71%" />
<col style="width: 29%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><strong>add_child</strong></p></td>
<td></td>
</tr>
<tr class="row-even"><td><p><strong>add_dependency</strong></p></td>
<td></td>
</tr>
<tr class="row-odd"><td><p><strong>add_feature</strong></p></td>
<td></td>
</tr>
<tr class="row-even"><td><p><strong>bind_arguments</strong></p></td>
<td></td>
</tr>
<tr class="row-odd"><td><p><strong>current_value</strong></p></td>
<td></td>
</tr>
<tr class="row-even"><td><p><strong>get_add</strong></p></td>
<td></td>
</tr>
<tr class="row-odd"><td><p><strong>get_citations</strong></p></td>
<td></td>
</tr>
<tr class="row-even"><td><p><strong>get_indexes</strong></p></td>
<td></td>
</tr>
<tr class="row-odd"><td><p><strong>get_mul</strong></p></td>
<td></td>
</tr>
<tr class="row-even"><td><p><strong>invalidate</strong></p></td>
<td></td>
</tr>
<tr class="row-odd"><td><p><strong>is_valid</strong></p></td>
<td></td>
</tr>
<tr class="row-even"><td><p><strong>previous</strong></p></td>
<td></td>
</tr>
<tr class="row-odd"><td><p><strong>recurse_children</strong></p></td>
<td></td>
</tr>
<tr class="row-even"><td><p><strong>recurse_dependencies</strong></p></td>
<td></td>
</tr>
<tr class="row-odd"><td><p><strong>seed</strong></p></td>
<td></td>
</tr>
<tr class="row-even"><td><p><strong>set_value</strong></p></td>
<td></td>
</tr>
<tr class="row-odd"><td><p><strong>store</strong></p></td>
<td></td>
</tr>
<tr class="row-even"><td><p><strong>update</strong></p></td>
<td></td>
</tr>
<tr class="row-odd"><td><p><strong>valid_index</strong></p></td>
<td></td>
</tr>
<tr class="row-even"><td><p><strong>validate</strong></p></td>
<td></td>
</tr>
</tbody>
</table>
</dd></dl>

</div>
</div>
</div>
<div class="section" id="generators">
<h2>generators<a class="headerlink" href="#generators" title="Permalink to this headline">¶</a></h2>
<div class="section" id="id2">
<h3>Module classes<a class="headerlink" href="#id2" title="Permalink to this headline">¶</a></h3>
<div class="section" id="autotrackgenerator">
<h4>AutoTrackGenerator<a class="headerlink" href="#autotrackgenerator" title="Permalink to this headline">¶</a></h4>
<dl class="class">
<dt id="deeptrack.models.AutoTrackGenerator">
<em class="property">class </em><code class="sig-prename descclassname">deeptrack.models.</code><code class="sig-name descname">AutoTrackGenerator</code><span class="sig-paren">(</span><em class="sig-param">feature</em>, <em class="sig-param">num_outputs=2</em>, <em class="sig-param">transformation_function=(&lt;deeptrack.features.Chain object&gt;</em>, <em class="sig-param">&lt;deeptrack.features.Chain object&gt;)</em>, <em class="sig-param">**kwargs</em><span class="sig-paren">)</span><a class="headerlink" href="#deeptrack.models.AutoTrackGenerator" title="Permalink to this definition">¶</a></dt>
<dd><p>Data generator for use with an AutoTracker.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>feature</strong><span class="classifier">Feature</span></dt><dd><p>DeepTrack feature returning crops of single objects.</p>
</dd>
<dt><strong>num_outputs</strong><span class="classifier">int</span></dt><dd><p>Number of values the model is expected to predict (not including the weight-map)</p>
</dd>
<dt><strong>transformation_function</strong><span class="classifier">Feature, Feature, optional</span></dt><dd><p>Tuple of features defining transformations applied to each crop as well as the corresponding equivariance.</p>
</dd>
</dl>
</dd>
</dl>
<p class="rubric">Methods</p>
<table class="longtable table autosummary">
<colgroup>
<col style="width: 10%" />
<col style="width: 90%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">on_epoch_end</span></code>()</p></td>
<td><p>Method called at the end of every epoch.</p></td>
</tr>
</tbody>
</table>
<table class="table">
<colgroup>
<col style="width: 71%" />
<col style="width: 29%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><strong>cleanup</strong></p></td>
<td></td>
</tr>
<tr class="row-even"><td><p><strong>construct_datapoint</strong></p></td>
<td></td>
</tr>
<tr class="row-odd"><td><p><strong>get_transform_matrix</strong></p></td>
<td></td>
</tr>
</tbody>
</table>
</dd></dl>

</div>
</div>
</div>
<div class="section" id="id3">
<h2>models<a class="headerlink" href="#id3" title="Permalink to this headline">¶</a></h2>
<div class="section" id="id4">
<h3>Module classes<a class="headerlink" href="#id4" title="Permalink to this headline">¶</a></h3>
<div class="section" id="automultitracker">
<h4>AutoMultiTracker<a class="headerlink" href="#automultitracker" title="Permalink to this headline">¶</a></h4>
<dl class="class">
<dt id="deeptrack.models.AutoMultiTracker">
<em class="property">class </em><code class="sig-prename descclassname">deeptrack.models.</code><code class="sig-name descname">AutoMultiTracker</code><span class="sig-paren">(</span><em class="sig-param">model=None</em>, <em class="sig-param">input_shape=(None</em>, <em class="sig-param">None</em>, <em class="sig-param">1)</em>, <em class="sig-param">loss='mae'</em>, <em class="sig-param">num_outputs=2</em>, <em class="sig-param">feature_weights=None</em>, <em class="sig-param">**kwargs</em><span class="sig-paren">)</span><a class="headerlink" href="#deeptrack.models.AutoMultiTracker" title="Permalink to this definition">¶</a></dt>
<dd><p>Model that automatically learns to track a multiple objects.</p>
<p>During training, expects ROIs of single objects. For best results, keep the size of
the ROIs small (40-70 px).</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>model</strong><span class="classifier">Tensorflow model, optional</span></dt><dd><p>A model that returns a (N, N, 2) array. If not defined,
a default model is used instead.</p>
</dd>
<dt><strong>loss, optimizer</strong><span class="classifier">compilation arguments</span></dt><dd><p>Keras arguments used to compile the model</p>
</dd>
</dl>
</dd>
</dl>
<p class="rubric">Methods</p>
<table class="longtable table autosummary">
<colgroup>
<col style="width: 10%" />
<col style="width: 90%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#deeptrack.models.AutoMultiTracker.AutoTrackerModel" title="deeptrack.models.AutoMultiTracker.AutoTrackerModel"><code class="xref py py-obj docutils literal notranslate"><span class="pre">AutoTrackerModel</span></code></a></p></td>
<td><p>alias of <a class="reference internal" href="#deeptrack.models.AutoTrackerBaseModel" title="deeptrack.models.AutoTrackerBaseModel"><code class="xref py py-class docutils literal notranslate"><span class="pre">AutoTrackerBaseModel</span></code></a></p></td>
</tr>
<tr class="row-even"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">__call__</span></code>(*args, **kwargs)</p></td>
<td><p>Call self as a function.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">action</span></code>([replicate_index])</p></td>
<td><p>Creates the image.</p></td>
</tr>
<tr class="row-even"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">data_generator</span></code></p></td>
<td><p>alias of <code class="xref py py-class docutils literal notranslate"><span class="pre">deeptrack.models.autotracking.generators.AutoTrackGenerator</span></code></p></td>
</tr>
<tr class="row-odd"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">detect</span></code>(pred, weights[, alpha, beta, cutoff, …])</p></td>
<td><p>Detects the objects in one frame.</p></td>
</tr>
<tr class="row-even"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">export</span></code>(path, minimum_size[, preprocessing, …])</p></td>
<td><p>Export model unto the BioImage Model Zoo format for use with Fiji and ImageJ.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">find_local_maxima</span></code>(pred, score[, cutoff, mode])</p></td>
<td><p>Finds the local maxima in a score-map, indicating detections</p></td>
</tr>
<tr class="row-even"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">fit</span></code>([x, y, batch_size, epochs, verbose, …])</p></td>
<td><p>Trains the model for a fixed number of epochs (iterations on a dataset).</p></td>
</tr>
<tr class="row-odd"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">get_detection_score</span></code>(pred, weights[, alpha, beta])</p></td>
<td><p>Calculates the detection score as weights^alpha * consistency ^ beta.</p></td>
</tr>
<tr class="row-even"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">local_consistency</span></code>(pred)</p></td>
<td><p>Calculate the consistency metric</p></td>
</tr>
<tr class="row-odd"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">plot</span></code>([input_image, resolve_kwargs, interval])</p></td>
<td><p>Visualizes the output of the feature.</p></td>
</tr>
<tr class="row-even"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">predict_and_detect</span></code>(data[, alpha, beta, …])</p></td>
<td><p>Evaluates the model on a batch of data, and detects objects in each frame</p></td>
</tr>
<tr class="row-odd"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">predict_and_pool</span></code>(data[, mask])</p></td>
<td><p>Evaluates the model on a batch of data, and pools the predictions in each frame to a single value.</p></td>
</tr>
<tr class="row-even"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">resolve</span></code>([image_list, replicate_index])</p></td>
<td><p>Call self as a function.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">sample</span></code>(**kwargs)</p></td>
<td><p>Returns the feature</p></td>
</tr>
</tbody>
</table>
<table class="table">
<colgroup>
<col style="width: 71%" />
<col style="width: 29%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><strong>add_child</strong></p></td>
<td></td>
</tr>
<tr class="row-even"><td><p><strong>add_dependency</strong></p></td>
<td></td>
</tr>
<tr class="row-odd"><td><p><strong>add_feature</strong></p></td>
<td></td>
</tr>
<tr class="row-even"><td><p><strong>add_preprocessing</strong></p></td>
<td></td>
</tr>
<tr class="row-odd"><td><p><strong>bind_arguments</strong></p></td>
<td></td>
</tr>
<tr class="row-even"><td><p><strong>current_value</strong></p></td>
<td></td>
</tr>
<tr class="row-odd"><td><p><strong>default_model</strong></p></td>
<td></td>
</tr>
<tr class="row-even"><td><p><strong>get_citations</strong></p></td>
<td></td>
</tr>
<tr class="row-odd"><td><p><strong>invalidate</strong></p></td>
<td></td>
</tr>
<tr class="row-even"><td><p><strong>is_valid</strong></p></td>
<td></td>
</tr>
<tr class="row-odd"><td><p><strong>previous</strong></p></td>
<td></td>
</tr>
<tr class="row-even"><td><p><strong>recurse_children</strong></p></td>
<td></td>
</tr>
<tr class="row-odd"><td><p><strong>recurse_dependencies</strong></p></td>
<td></td>
</tr>
<tr class="row-even"><td><p><strong>seed</strong></p></td>
<td></td>
</tr>
<tr class="row-odd"><td><p><strong>set_value</strong></p></td>
<td></td>
</tr>
<tr class="row-even"><td><p><strong>store</strong></p></td>
<td></td>
</tr>
<tr class="row-odd"><td><p><strong>update</strong></p></td>
<td></td>
</tr>
<tr class="row-even"><td><p><strong>valid_index</strong></p></td>
<td></td>
</tr>
<tr class="row-odd"><td><p><strong>validate</strong></p></td>
<td></td>
</tr>
</tbody>
</table>
<dl class="attribute">
<dt id="deeptrack.models.AutoMultiTracker.AutoTrackerModel">
<code class="sig-name descname">AutoTrackerModel</code><a class="headerlink" href="#deeptrack.models.AutoMultiTracker.AutoTrackerModel" title="Permalink to this definition">¶</a></dt>
<dd><p>alias of <a class="reference internal" href="#deeptrack.models.AutoTrackerBaseModel" title="deeptrack.models.AutoTrackerBaseModel"><code class="xref py py-class docutils literal notranslate"><span class="pre">AutoTrackerBaseModel</span></code></a></p>
</dd></dl>

</dd></dl>

</div>
<div class="section" id="autotracker">
<h4>AutoTracker<a class="headerlink" href="#autotracker" title="Permalink to this headline">¶</a></h4>
<dl class="class">
<dt id="deeptrack.models.AutoTracker">
<em class="property">class </em><code class="sig-prename descclassname">deeptrack.models.</code><code class="sig-name descname">AutoTracker</code><span class="sig-paren">(</span><em class="sig-param">model=None</em>, <em class="sig-param">input_shape=(None</em>, <em class="sig-param">None</em>, <em class="sig-param">1)</em>, <em class="sig-param">loss='mae'</em>, <em class="sig-param">num_outputs=2</em>, <em class="sig-param">feature_weights=None</em>, <em class="sig-param">**kwargs</em><span class="sig-paren">)</span><a class="headerlink" href="#deeptrack.models.AutoTracker" title="Permalink to this definition">¶</a></dt>
<dd><p>Model that automatically learns to track a single object.</p>
<p>For best results, keep the size of the images small (40-70 px).</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>model</strong><span class="classifier">Tensorflow model, optional</span></dt><dd><p>A model that returns a vector of two numbers. If not defined,
a default model is used instead.</p>
</dd>
<dt><strong>input_shape</strong><span class="classifier">tuple of ints</span></dt><dd><p>Shape of the input images. Should match the expected shape of the model.</p>
</dd>
<dt><strong>loss, optimizer</strong><span class="classifier">compilation arguments</span></dt><dd><p>Keras arguments used to compile the model</p>
</dd>
</dl>
</dd>
</dl>
<p class="rubric">Methods</p>
<table class="longtable table autosummary">
<colgroup>
<col style="width: 10%" />
<col style="width: 90%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#deeptrack.models.AutoTracker.AutoTrackerModel" title="deeptrack.models.AutoTracker.AutoTrackerModel"><code class="xref py py-obj docutils literal notranslate"><span class="pre">AutoTrackerModel</span></code></a>(model[, feature_weights])</p></td>
<td><p><dl class="field-list simple">
<dt class="field-odd">Attributes</dt>
<dd class="field-odd"><p></p></dd>
</dl>
</p></td>
</tr>
<tr class="row-even"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">__call__</span></code>(*args, **kwargs)</p></td>
<td><p>Call self as a function.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">action</span></code>([replicate_index])</p></td>
<td><p>Creates the image.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#deeptrack.models.AutoTracker.data_generator" title="deeptrack.models.AutoTracker.data_generator"><code class="xref py py-obj docutils literal notranslate"><span class="pre">data_generator</span></code></a></p></td>
<td><p>alias of <code class="xref py py-class docutils literal notranslate"><span class="pre">deeptrack.models.autotracking.generators.AutoTrackGenerator</span></code></p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#deeptrack.models.AutoTracker.detect" title="deeptrack.models.AutoTracker.detect"><code class="xref py py-obj docutils literal notranslate"><span class="pre">detect</span></code></a>(pred, weights[, alpha, beta, cutoff, …])</p></td>
<td><p>Detects the objects in one frame.</p></td>
</tr>
<tr class="row-even"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">export</span></code>(path, minimum_size[, preprocessing, …])</p></td>
<td><p>Export model unto the BioImage Model Zoo format for use with Fiji and ImageJ.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#deeptrack.models.AutoTracker.find_local_maxima" title="deeptrack.models.AutoTracker.find_local_maxima"><code class="xref py py-obj docutils literal notranslate"><span class="pre">find_local_maxima</span></code></a>(pred, score[, cutoff, mode])</p></td>
<td><p>Finds the local maxima in a score-map, indicating detections</p></td>
</tr>
<tr class="row-even"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">fit</span></code>([x, y, batch_size, epochs, verbose, …])</p></td>
<td><p>Trains the model for a fixed number of epochs (iterations on a dataset).</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#deeptrack.models.AutoTracker.get_detection_score" title="deeptrack.models.AutoTracker.get_detection_score"><code class="xref py py-obj docutils literal notranslate"><span class="pre">get_detection_score</span></code></a>(pred, weights[, alpha, beta])</p></td>
<td><p>Calculates the detection score as weights^alpha * consistency ^ beta.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#deeptrack.models.AutoTracker.local_consistency" title="deeptrack.models.AutoTracker.local_consistency"><code class="xref py py-obj docutils literal notranslate"><span class="pre">local_consistency</span></code></a>(pred)</p></td>
<td><p>Calculate the consistency metric</p></td>
</tr>
<tr class="row-odd"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">plot</span></code>([input_image, resolve_kwargs, interval])</p></td>
<td><p>Visualizes the output of the feature.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#deeptrack.models.AutoTracker.predict_and_detect" title="deeptrack.models.AutoTracker.predict_and_detect"><code class="xref py py-obj docutils literal notranslate"><span class="pre">predict_and_detect</span></code></a>(data[, alpha, beta, …])</p></td>
<td><p>Evaluates the model on a batch of data, and detects objects in each frame</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#deeptrack.models.AutoTracker.predict_and_pool" title="deeptrack.models.AutoTracker.predict_and_pool"><code class="xref py py-obj docutils literal notranslate"><span class="pre">predict_and_pool</span></code></a>(data[, mask])</p></td>
<td><p>Evaluates the model on a batch of data, and pools the predictions in each frame to a single value.</p></td>
</tr>
<tr class="row-even"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">resolve</span></code>([image_list, replicate_index])</p></td>
<td><p>Call self as a function.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">sample</span></code>(**kwargs)</p></td>
<td><p>Returns the feature</p></td>
</tr>
</tbody>
</table>
<table class="table">
<colgroup>
<col style="width: 71%" />
<col style="width: 29%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><strong>add_child</strong></p></td>
<td></td>
</tr>
<tr class="row-even"><td><p><strong>add_dependency</strong></p></td>
<td></td>
</tr>
<tr class="row-odd"><td><p><strong>add_feature</strong></p></td>
<td></td>
</tr>
<tr class="row-even"><td><p><strong>add_preprocessing</strong></p></td>
<td></td>
</tr>
<tr class="row-odd"><td><p><strong>bind_arguments</strong></p></td>
<td></td>
</tr>
<tr class="row-even"><td><p><strong>current_value</strong></p></td>
<td></td>
</tr>
<tr class="row-odd"><td><p><strong>default_model</strong></p></td>
<td></td>
</tr>
<tr class="row-even"><td><p><strong>get_citations</strong></p></td>
<td></td>
</tr>
<tr class="row-odd"><td><p><strong>invalidate</strong></p></td>
<td></td>
</tr>
<tr class="row-even"><td><p><strong>is_valid</strong></p></td>
<td></td>
</tr>
<tr class="row-odd"><td><p><strong>previous</strong></p></td>
<td></td>
</tr>
<tr class="row-even"><td><p><strong>recurse_children</strong></p></td>
<td></td>
</tr>
<tr class="row-odd"><td><p><strong>recurse_dependencies</strong></p></td>
<td></td>
</tr>
<tr class="row-even"><td><p><strong>seed</strong></p></td>
<td></td>
</tr>
<tr class="row-odd"><td><p><strong>set_value</strong></p></td>
<td></td>
</tr>
<tr class="row-even"><td><p><strong>store</strong></p></td>
<td></td>
</tr>
<tr class="row-odd"><td><p><strong>update</strong></p></td>
<td></td>
</tr>
<tr class="row-even"><td><p><strong>valid_index</strong></p></td>
<td></td>
</tr>
<tr class="row-odd"><td><p><strong>validate</strong></p></td>
<td></td>
</tr>
</tbody>
</table>
<dl class="class">
<dt id="deeptrack.models.AutoTracker.AutoTrackerModel">
<em class="property">class </em><code class="sig-name descname">AutoTrackerModel</code><span class="sig-paren">(</span><em class="sig-param">model</em>, <em class="sig-param">feature_weights=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deeptrack.models.AutoTracker.AutoTrackerModel" title="Permalink to this definition">¶</a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Attributes</dt>
<dd class="field-odd"><dl class="simple">
<dt><code class="xref py py-obj docutils literal notranslate"><span class="pre">activity_regularizer</span></code></dt><dd><p>Optional regularizer function for the output of this layer.</p>
</dd>
<dt><code class="xref py py-obj docutils literal notranslate"><span class="pre">compute_dtype</span></code></dt><dd><p>The dtype of the layer’s computations.</p>
</dd>
<dt><code class="xref py py-obj docutils literal notranslate"><span class="pre">distribute_strategy</span></code></dt><dd><p>The <cite>tf.distribute.Strategy</cite> this model was created under.</p>
</dd>
<dt><code class="xref py py-obj docutils literal notranslate"><span class="pre">dtype</span></code></dt><dd><p>The dtype of the layer weights.</p>
</dd>
<dt><code class="xref py py-obj docutils literal notranslate"><span class="pre">dtype_policy</span></code></dt><dd><p>The dtype policy associated with this layer.</p>
</dd>
<dt><code class="xref py py-obj docutils literal notranslate"><span class="pre">dynamic</span></code></dt><dd><p>Whether the layer is dynamic (eager-only); set in the constructor.</p>
</dd>
<dt><code class="xref py py-obj docutils literal notranslate"><span class="pre">inbound_nodes</span></code></dt><dd><p>Deprecated, do NOT use! Only for compatibility with external Keras.</p>
</dd>
<dt><code class="xref py py-obj docutils literal notranslate"><span class="pre">input</span></code></dt><dd><p>Retrieves the input tensor(s) of a layer.</p>
</dd>
<dt><code class="xref py py-obj docutils literal notranslate"><span class="pre">input_mask</span></code></dt><dd><p>Retrieves the input mask tensor(s) of a layer.</p>
</dd>
<dt><code class="xref py py-obj docutils literal notranslate"><span class="pre">input_shape</span></code></dt><dd><p>Retrieves the input shape(s) of a layer.</p>
</dd>
<dt><code class="xref py py-obj docutils literal notranslate"><span class="pre">input_spec</span></code></dt><dd><p><cite>InputSpec</cite> instance(s) describing the input format for this layer.</p>
</dd>
<dt><strong>layers</strong></dt><dd></dd>
<dt><code class="xref py py-obj docutils literal notranslate"><span class="pre">losses</span></code></dt><dd><p>List of losses added using the <cite>add_loss()</cite> API.</p>
</dd>
<dt><code class="xref py py-obj docutils literal notranslate"><span class="pre">metrics</span></code></dt><dd><p>Returns the model’s metrics added using <cite>compile</cite>, <cite>add_metric</cite> APIs.</p>
</dd>
<dt><code class="xref py py-obj docutils literal notranslate"><span class="pre">metrics_names</span></code></dt><dd><p>Returns the model’s display labels for all outputs.</p>
</dd>
<dt><code class="xref py py-obj docutils literal notranslate"><span class="pre">name</span></code></dt><dd><p>Name of the layer (string), set in the constructor.</p>
</dd>
<dt><code class="xref py py-obj docutils literal notranslate"><span class="pre">name_scope</span></code></dt><dd><p>Returns a <cite>tf.name_scope</cite> instance for this class.</p>
</dd>
<dt><strong>non_trainable_variables</strong></dt><dd></dd>
<dt><code class="xref py py-obj docutils literal notranslate"><span class="pre">non_trainable_weights</span></code></dt><dd><p>List of all non-trainable weights tracked by this layer.</p>
</dd>
<dt><code class="xref py py-obj docutils literal notranslate"><span class="pre">outbound_nodes</span></code></dt><dd><p>Deprecated, do NOT use! Only for compatibility with external Keras.</p>
</dd>
<dt><code class="xref py py-obj docutils literal notranslate"><span class="pre">output</span></code></dt><dd><p>Retrieves the output tensor(s) of a layer.</p>
</dd>
<dt><code class="xref py py-obj docutils literal notranslate"><span class="pre">output_mask</span></code></dt><dd><p>Retrieves the output mask tensor(s) of a layer.</p>
</dd>
<dt><code class="xref py py-obj docutils literal notranslate"><span class="pre">output_shape</span></code></dt><dd><p>Retrieves the output shape(s) of a layer.</p>
</dd>
<dt><code class="xref py py-obj docutils literal notranslate"><span class="pre">run_eagerly</span></code></dt><dd><p>Settable attribute indicating whether the model should run eagerly.</p>
</dd>
<dt><code class="xref py py-obj docutils literal notranslate"><span class="pre">state_updates</span></code></dt><dd><p>Deprecated, do NOT use!</p>
</dd>
<dt><strong>stateful</strong></dt><dd></dd>
<dt><code class="xref py py-obj docutils literal notranslate"><span class="pre">submodules</span></code></dt><dd><p>Sequence of all sub-modules.</p>
</dd>
<dt><code class="xref py py-obj docutils literal notranslate"><span class="pre">supports_masking</span></code></dt><dd><p>Whether this layer supports computing a mask using <cite>compute_mask</cite>.</p>
</dd>
<dt><strong>trainable</strong></dt><dd></dd>
<dt><code class="xref py py-obj docutils literal notranslate"><span class="pre">trainable_variables</span></code></dt><dd><p>Sequence of trainable variables owned by this module and its submodules.</p>
</dd>
<dt><code class="xref py py-obj docutils literal notranslate"><span class="pre">trainable_weights</span></code></dt><dd><p>List of all trainable weights tracked by this layer.</p>
</dd>
<dt><strong>updates</strong></dt><dd></dd>
<dt><code class="xref py py-obj docutils literal notranslate"><span class="pre">variable_dtype</span></code></dt><dd><p>Alias of <cite>Layer.dtype</cite>, the dtype of the weights.</p>
</dd>
<dt><code class="xref py py-obj docutils literal notranslate"><span class="pre">variables</span></code></dt><dd><p>Returns the list of all layer variables/weights.</p>
</dd>
<dt><code class="xref py py-obj docutils literal notranslate"><span class="pre">weights</span></code></dt><dd><p>Returns the list of all layer variables/weights.</p>
</dd>
</dl>
</dd>
</dl>
<p class="rubric">Methods</p>
<table class="longtable table autosummary">
<colgroup>
<col style="width: 10%" />
<col style="width: 90%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">__call__</span></code>(*args, **kwargs)</p></td>
<td><p>Wraps <cite>call</cite>, applying pre- and post-processing steps.</p></td>
</tr>
<tr class="row-even"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">add_loss</span></code>(losses, **kwargs)</p></td>
<td><p>Add loss tensor(s), potentially dependent on layer inputs.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">add_metric</span></code>(value[, name])</p></td>
<td><p>Adds metric tensor to the layer.</p></td>
</tr>
<tr class="row-even"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">add_update</span></code>(updates[, inputs])</p></td>
<td><p>Add update op(s), potentially dependent on layer inputs.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">add_variable</span></code>(*args, **kwargs)</p></td>
<td><p>Deprecated, do NOT use! Alias for <cite>add_weight</cite>.</p></td>
</tr>
<tr class="row-even"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">add_weight</span></code>([name, shape, dtype, …])</p></td>
<td><p>Adds a new variable to the layer.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">apply</span></code>(inputs, *args, **kwargs)</p></td>
<td><p>Deprecated, do NOT use!</p></td>
</tr>
<tr class="row-even"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">build</span></code>(input_shape)</p></td>
<td><p>Builds the model based on input shapes received.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#deeptrack.models.AutoTracker.AutoTrackerModel.call" title="deeptrack.models.AutoTracker.AutoTrackerModel.call"><code class="xref py py-obj docutils literal notranslate"><span class="pre">call</span></code></a>(x[, training])</p></td>
<td><p>Calls the model on new inputs.</p></td>
</tr>
<tr class="row-even"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">compile</span></code>(*args, **kwargs)</p></td>
<td><p>Configures the model for training.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">compute_mask</span></code>(inputs[, mask])</p></td>
<td><p>Computes an output mask tensor.</p></td>
</tr>
<tr class="row-even"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">compute_output_shape</span></code>(input_shape)</p></td>
<td><p>Computes the output shape of the layer.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">compute_output_signature</span></code>(input_signature)</p></td>
<td><p>Compute the output tensor signature of the layer based on the inputs.</p></td>
</tr>
<tr class="row-even"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">count_params</span></code>()</p></td>
<td><p>Count the total number of scalars composing the weights.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">evaluate</span></code>([x, y, batch_size, verbose, …])</p></td>
<td><p>Returns the loss value &amp; metrics values for the model in test mode.</p></td>
</tr>
<tr class="row-even"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">evaluate_generator</span></code>(generator[, steps, …])</p></td>
<td><p>Evaluates the model on a data generator.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">fit</span></code>([x, y, batch_size, epochs, verbose, …])</p></td>
<td><p>Trains the model for a fixed number of epochs (iterations on a dataset).</p></td>
</tr>
<tr class="row-even"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">fit_generator</span></code>(generator[, steps_per_epoch, …])</p></td>
<td><p>Fits the model on data yielded batch-by-batch by a Python generator.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">from_config</span></code>(config)</p></td>
<td><p>Creates a layer from its config.</p></td>
</tr>
<tr class="row-even"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">get_config</span></code>()</p></td>
<td><p>Returns the config of the layer.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">get_input_at</span></code>(node_index)</p></td>
<td><p>Retrieves the input tensor(s) of a layer at a given node.</p></td>
</tr>
<tr class="row-even"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">get_input_mask_at</span></code>(node_index)</p></td>
<td><p>Retrieves the input mask tensor(s) of a layer at a given node.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">get_input_shape_at</span></code>(node_index)</p></td>
<td><p>Retrieves the input shape(s) of a layer at a given node.</p></td>
</tr>
<tr class="row-even"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">get_layer</span></code>([name, index])</p></td>
<td><p>Retrieves a layer based on either its name (unique) or index.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">get_losses_for</span></code>(inputs)</p></td>
<td><p>Deprecated, do NOT use!</p></td>
</tr>
<tr class="row-even"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">get_output_at</span></code>(node_index)</p></td>
<td><p>Retrieves the output tensor(s) of a layer at a given node.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">get_output_mask_at</span></code>(node_index)</p></td>
<td><p>Retrieves the output mask tensor(s) of a layer at a given node.</p></td>
</tr>
<tr class="row-even"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">get_output_shape_at</span></code>(node_index)</p></td>
<td><p>Retrieves the output shape(s) of a layer at a given node.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">get_updates_for</span></code>(inputs)</p></td>
<td><p>Deprecated, do NOT use!</p></td>
</tr>
<tr class="row-even"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">get_weights</span></code>()</p></td>
<td><p>Retrieves the weights of the model.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">load_weights</span></code>(filepath[, by_name, …])</p></td>
<td><p>Loads all layer weights, either from a TensorFlow or an HDF5 weight file.</p></td>
</tr>
<tr class="row-even"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">make_predict_function</span></code>()</p></td>
<td><p>Creates a function that executes one step of inference.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">make_test_function</span></code>()</p></td>
<td><p>Creates a function that executes one step of evaluation.</p></td>
</tr>
<tr class="row-even"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">make_train_function</span></code>()</p></td>
<td><p>Creates a function that executes one step of training.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">predict</span></code>(x[, batch_size, verbose, steps, …])</p></td>
<td><p>Generates output predictions for the input samples.</p></td>
</tr>
<tr class="row-even"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">predict_generator</span></code>(generator[, steps, …])</p></td>
<td><p>Generates predictions for the input samples from a data generator.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">predict_on_batch</span></code>(x)</p></td>
<td><p>Returns predictions for a single batch of samples.</p></td>
</tr>
<tr class="row-even"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">predict_step</span></code>(data)</p></td>
<td><p>The logic for one inference step.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">reset_metrics</span></code>()</p></td>
<td><p>Resets the state of all the metrics in the model.</p></td>
</tr>
<tr class="row-even"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">save</span></code>(filepath[, overwrite, …])</p></td>
<td><p>Saves the model to Tensorflow SavedModel or a single HDF5 file.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">save_weights</span></code>(filepath[, overwrite, …])</p></td>
<td><p>Saves all layer weights.</p></td>
</tr>
<tr class="row-even"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">set_weights</span></code>(weights)</p></td>
<td><p>Sets the weights of the layer, from Numpy arrays.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">summary</span></code>([line_length, positions, print_fn])</p></td>
<td><p>Prints a string summary of the network.</p></td>
</tr>
<tr class="row-even"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">test_on_batch</span></code>(x[, y, sample_weight, …])</p></td>
<td><p>Test the model on a single batch of samples.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">test_step</span></code>(data)</p></td>
<td><p>The logic for one evaluation step.</p></td>
</tr>
<tr class="row-even"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">to_json</span></code>(**kwargs)</p></td>
<td><p>Returns a JSON string containing the network configuration.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">to_yaml</span></code>(**kwargs)</p></td>
<td><p>Returns a yaml string containing the network configuration.</p></td>
</tr>
<tr class="row-even"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">train_on_batch</span></code>(x[, y, sample_weight, …])</p></td>
<td><p>Runs a single gradient update on a single batch of data.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">train_step</span></code>(data)</p></td>
<td><p>The logic for one training step.</p></td>
</tr>
<tr class="row-even"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">with_name_scope</span></code>(method)</p></td>
<td><p>Decorator to automatically enter the module name scope.</p></td>
</tr>
</tbody>
</table>
<table class="table">
<colgroup>
<col style="width: 62%" />
<col style="width: 38%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><strong>global_pool</strong></p></td>
<td></td>
</tr>
<tr class="row-even"><td><p><strong>reset_states</strong></p></td>
<td></td>
</tr>
<tr class="row-odd"><td><p><strong>softmax</strong></p></td>
<td></td>
</tr>
</tbody>
</table>
<dl class="method">
<dt id="deeptrack.models.AutoTracker.AutoTrackerModel.call">
<code class="sig-name descname">call</code><span class="sig-paren">(</span><em class="sig-param">x</em>, <em class="sig-param">training=False</em><span class="sig-paren">)</span><a class="headerlink" href="#deeptrack.models.AutoTracker.AutoTrackerModel.call" title="Permalink to this definition">¶</a></dt>
<dd><p>Calls the model on new inputs.</p>
<p>In this case <cite>call</cite> just reapplies
all ops in the graph to the new inputs
(e.g. build a new computational graph from the provided inputs).</p>
<dl>
<dt>Arguments:</dt><dd><p>inputs: A tensor or list of tensors.
training: Boolean or boolean scalar tensor, indicating whether to run</p>
<blockquote>
<div><p>the <cite>Network</cite> in training mode or inference mode.</p>
</div></blockquote>
<dl class="simple">
<dt>mask: A mask or list of masks. A mask can be</dt><dd><p>either a tensor or None (no mask).</p>
</dd>
</dl>
</dd>
<dt>Returns:</dt><dd><p>A tensor if there is a single output, or
a list of tensors if there are more than one outputs.</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="attribute">
<dt id="deeptrack.models.AutoTracker.data_generator">
<code class="sig-name descname">data_generator</code><a class="headerlink" href="#deeptrack.models.AutoTracker.data_generator" title="Permalink to this definition">¶</a></dt>
<dd><p>alias of <code class="xref py py-class docutils literal notranslate"><span class="pre">deeptrack.models.autotracking.generators.AutoTrackGenerator</span></code></p>
</dd></dl>

<dl class="method">
<dt id="deeptrack.models.AutoTracker.detect">
<code class="sig-name descname">detect</code><span class="sig-paren">(</span><em class="sig-param">pred</em>, <em class="sig-param">weights</em>, <em class="sig-param">alpha=0.5</em>, <em class="sig-param">beta=0.5</em>, <em class="sig-param">cutoff=0.95</em>, <em class="sig-param">mode='quantile'</em><span class="sig-paren">)</span><a class="headerlink" href="#deeptrack.models.AutoTracker.detect" title="Permalink to this definition">¶</a></dt>
<dd><p>Detects the objects in one frame.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>pred, weights: array-like</strong></dt><dd><p>Output from model</p>
</dd>
<dt><strong>alpha, beta: float</strong></dt><dd><p>Geometric weight of the weight-map vs the consistenct metric for detection.</p>
</dd>
<dt><strong>cutoff, mode: float, string</strong></dt><dd><p>Treshholding parameters. Mode can be either “quantile” or “ratio” or “constant”. If “quantile”, then
<cite>ratio</cite> defines the quantile of scores to accept. If “ratio”, then cutoff defines the ratio of the max
score as threshhold. If constant, the cutoff is used directly as treshhold.</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="deeptrack.models.AutoTracker.find_local_maxima">
<em class="property">static </em><code class="sig-name descname">find_local_maxima</code><span class="sig-paren">(</span><em class="sig-param">pred</em>, <em class="sig-param">score</em>, <em class="sig-param">cutoff=0.9</em>, <em class="sig-param">mode='quantile'</em><span class="sig-paren">)</span><a class="headerlink" href="#deeptrack.models.AutoTracker.find_local_maxima" title="Permalink to this definition">¶</a></dt>
<dd><p>Finds the local maxima in a score-map, indicating detections</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>pred, score: array-like</strong></dt><dd><p>Output from model, score-map</p>
</dd>
<dt><strong>cutoff, mode: float, string</strong></dt><dd><p>Treshholding parameters. Mode can be either “quantile” or “ratio” or “constant”. If “quantile”, then
<cite>ratio</cite> defines the quantile of scores to accept. If “ratio”, then cutoff defines the ratio of the max
score as threshhold. If constant, the cutoff is used directly as treshhold.</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="deeptrack.models.AutoTracker.get_detection_score">
<code class="sig-name descname">get_detection_score</code><span class="sig-paren">(</span><em class="sig-param">pred</em>, <em class="sig-param">weights</em>, <em class="sig-param">alpha=0.5</em>, <em class="sig-param">beta=0.5</em><span class="sig-paren">)</span><a class="headerlink" href="#deeptrack.models.AutoTracker.get_detection_score" title="Permalink to this definition">¶</a></dt>
<dd><p>Calculates the detection score as weights^alpha * consistency ^ beta.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>pred, weights: array-like</strong></dt><dd><p>Output from model</p>
</dd>
<dt><strong>alpha, beta: float</strong></dt><dd><p>Geometric weight of the weight-map vs the consistenct metric for detection.</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="deeptrack.models.AutoTracker.local_consistency">
<em class="property">static </em><code class="sig-name descname">local_consistency</code><span class="sig-paren">(</span><em class="sig-param">pred</em><span class="sig-paren">)</span><a class="headerlink" href="#deeptrack.models.AutoTracker.local_consistency" title="Permalink to this definition">¶</a></dt>
<dd><p>Calculate the consistency metric</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>pred</strong><span class="classifier">array-like</span></dt><dd><p>first output from model</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="deeptrack.models.AutoTracker.predict_and_detect">
<code class="sig-name descname">predict_and_detect</code><span class="sig-paren">(</span><em class="sig-param">data</em>, <em class="sig-param">alpha=0.5</em>, <em class="sig-param">beta=0.5</em>, <em class="sig-param">cutoff=0.98</em>, <em class="sig-param">mode='quantile'</em><span class="sig-paren">)</span><a class="headerlink" href="#deeptrack.models.AutoTracker.predict_and_detect" title="Permalink to this definition">¶</a></dt>
<dd><p>Evaluates the model on a batch of data, and detects objects in each frame</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>data: array-like</strong></dt><dd><p>Data to predict on</p>
</dd>
<dt><strong>alpha, beta: float</strong></dt><dd><p>Geometric weight of the weight-map vs the consistenct metric for detection.</p>
</dd>
<dt><strong>cutoff, mode: float, string</strong></dt><dd><p>Treshholding parameters. Mode can be either “quantile” or “ratio” or “constant”. If “quantile”, then
<cite>ratio</cite> defines the quantile of scores to accept. If “ratio”, then cutoff defines the ratio of the max
score as threshhold. If constant, the cutoff is used directly as treshhold.</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="deeptrack.models.AutoTracker.predict_and_pool">
<code class="sig-name descname">predict_and_pool</code><span class="sig-paren">(</span><em class="sig-param">data</em>, <em class="sig-param">mask=1</em><span class="sig-paren">)</span><a class="headerlink" href="#deeptrack.models.AutoTracker.predict_and_pool" title="Permalink to this definition">¶</a></dt>
<dd><p>Evaluates the model on a batch of data, and pools the predictions in each frame to a single value.
Used when it’s known a-priori that there is only one object per image.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>data: array-like</strong></dt><dd><p>Data to predict on.</p>
</dd>
<dt><strong>mask: array-like</strong></dt><dd><p>Optional mask to filter out regions of the image before pooling.</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

</dd></dl>

</div>
<div class="section" id="autotrackerbasemodel">
<h4>AutoTrackerBaseModel<a class="headerlink" href="#autotrackerbasemodel" title="Permalink to this headline">¶</a></h4>
<dl class="class">
<dt id="deeptrack.models.AutoTrackerBaseModel">
<em class="property">class </em><code class="sig-prename descclassname">deeptrack.models.</code><code class="sig-name descname">AutoTrackerBaseModel</code><span class="sig-paren">(</span><em class="sig-param">model</em>, <em class="sig-param">feature_weights=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deeptrack.models.AutoTrackerBaseModel" title="Permalink to this definition">¶</a></dt>
<dd><p>Base wrapper for self-reinforced tracking models</p>
<p>Learns to solve problems of the form:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">y_i</span> <span class="o">=</span> <span class="n">A_i</span> <span class="o">+</span> <span class="n">f</span><span class="p">(</span><span class="n">x_0</span><span class="p">)</span> <span class="o">@</span> <span class="n">B_i</span>
</pre></div>
</div>
<p>where &#64; denotes matrix multiplication. Expects training data formated as:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="p">(</span><span class="n">A</span><span class="p">,</span> <span class="n">B</span><span class="p">))</span>
</pre></div>
</div>
<p>The implementation also supports defining additional constraints on the solution
by overriding the <cite>call</cite> method, by having it return additional values. The model
is trained to keep the constraints at zero. For example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">call</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">training</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
   <span class="n">y</span> <span class="o">=</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">call</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
   <span class="k">if</span> <span class="n">training</span><span class="p">:</span>
      <span class="n">constraint_0</span> <span class="o">=</span> <span class="n">K</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">K</span><span class="o">.</span><span class="n">square</span><span class="p">(</span><span class="n">y</span><span class="p">),</span> <span class="n">axis</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">))</span> <span class="o">-</span> <span class="mi">1</span>
      <span class="n">constraint_1</span> <span class="o">=</span> <span class="n">K</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">))</span>
      <span class="k">return</span> <span class="n">y</span><span class="p">,</span> <span class="n">constraint_0</span><span class="p">,</span> <span class="n">constraint_1</span>
   <span class="k">else</span><span class="p">:</span>
      <span class="k">return</span> <span class="n">y</span>
</pre></div>
</div>
<p>where the model is trained such that sum(y^2) == 1 and sum(y) == 0.</p>
<p>If used to predict a vector, use the call function to add a dimension such that the shape
matches (batch_dim, vector_dim, 1).</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>model</strong><span class="classifier">Tensorflow model</span></dt><dd><p>Model to wrap</p>
</dd>
</dl>
</dd>
<dt class="field-even">Attributes</dt>
<dd class="field-even"><dl class="simple">
<dt><code class="xref py py-obj docutils literal notranslate"><span class="pre">activity_regularizer</span></code></dt><dd><p>Optional regularizer function for the output of this layer.</p>
</dd>
<dt><code class="xref py py-obj docutils literal notranslate"><span class="pre">compute_dtype</span></code></dt><dd><p>The dtype of the layer’s computations.</p>
</dd>
<dt><code class="xref py py-obj docutils literal notranslate"><span class="pre">distribute_strategy</span></code></dt><dd><p>The <cite>tf.distribute.Strategy</cite> this model was created under.</p>
</dd>
<dt><code class="xref py py-obj docutils literal notranslate"><span class="pre">dtype</span></code></dt><dd><p>The dtype of the layer weights.</p>
</dd>
<dt><code class="xref py py-obj docutils literal notranslate"><span class="pre">dtype_policy</span></code></dt><dd><p>The dtype policy associated with this layer.</p>
</dd>
<dt><code class="xref py py-obj docutils literal notranslate"><span class="pre">dynamic</span></code></dt><dd><p>Whether the layer is dynamic (eager-only); set in the constructor.</p>
</dd>
<dt><code class="xref py py-obj docutils literal notranslate"><span class="pre">inbound_nodes</span></code></dt><dd><p>Deprecated, do NOT use! Only for compatibility with external Keras.</p>
</dd>
<dt><code class="xref py py-obj docutils literal notranslate"><span class="pre">input</span></code></dt><dd><p>Retrieves the input tensor(s) of a layer.</p>
</dd>
<dt><code class="xref py py-obj docutils literal notranslate"><span class="pre">input_mask</span></code></dt><dd><p>Retrieves the input mask tensor(s) of a layer.</p>
</dd>
<dt><code class="xref py py-obj docutils literal notranslate"><span class="pre">input_shape</span></code></dt><dd><p>Retrieves the input shape(s) of a layer.</p>
</dd>
<dt><code class="xref py py-obj docutils literal notranslate"><span class="pre">input_spec</span></code></dt><dd><p><cite>InputSpec</cite> instance(s) describing the input format for this layer.</p>
</dd>
<dt><strong>layers</strong></dt><dd></dd>
<dt><code class="xref py py-obj docutils literal notranslate"><span class="pre">losses</span></code></dt><dd><p>List of losses added using the <cite>add_loss()</cite> API.</p>
</dd>
<dt><code class="xref py py-obj docutils literal notranslate"><span class="pre">metrics</span></code></dt><dd><p>Returns the model’s metrics added using <cite>compile</cite>, <cite>add_metric</cite> APIs.</p>
</dd>
<dt><code class="xref py py-obj docutils literal notranslate"><span class="pre">metrics_names</span></code></dt><dd><p>Returns the model’s display labels for all outputs.</p>
</dd>
<dt><code class="xref py py-obj docutils literal notranslate"><span class="pre">name</span></code></dt><dd><p>Name of the layer (string), set in the constructor.</p>
</dd>
<dt><code class="xref py py-obj docutils literal notranslate"><span class="pre">name_scope</span></code></dt><dd><p>Returns a <cite>tf.name_scope</cite> instance for this class.</p>
</dd>
<dt><strong>non_trainable_variables</strong></dt><dd></dd>
<dt><code class="xref py py-obj docutils literal notranslate"><span class="pre">non_trainable_weights</span></code></dt><dd><p>List of all non-trainable weights tracked by this layer.</p>
</dd>
<dt><code class="xref py py-obj docutils literal notranslate"><span class="pre">outbound_nodes</span></code></dt><dd><p>Deprecated, do NOT use! Only for compatibility with external Keras.</p>
</dd>
<dt><code class="xref py py-obj docutils literal notranslate"><span class="pre">output</span></code></dt><dd><p>Retrieves the output tensor(s) of a layer.</p>
</dd>
<dt><code class="xref py py-obj docutils literal notranslate"><span class="pre">output_mask</span></code></dt><dd><p>Retrieves the output mask tensor(s) of a layer.</p>
</dd>
<dt><code class="xref py py-obj docutils literal notranslate"><span class="pre">output_shape</span></code></dt><dd><p>Retrieves the output shape(s) of a layer.</p>
</dd>
<dt><code class="xref py py-obj docutils literal notranslate"><span class="pre">run_eagerly</span></code></dt><dd><p>Settable attribute indicating whether the model should run eagerly.</p>
</dd>
<dt><code class="xref py py-obj docutils literal notranslate"><span class="pre">state_updates</span></code></dt><dd><p>Deprecated, do NOT use!</p>
</dd>
<dt><strong>stateful</strong></dt><dd></dd>
<dt><code class="xref py py-obj docutils literal notranslate"><span class="pre">submodules</span></code></dt><dd><p>Sequence of all sub-modules.</p>
</dd>
<dt><code class="xref py py-obj docutils literal notranslate"><span class="pre">supports_masking</span></code></dt><dd><p>Whether this layer supports computing a mask using <cite>compute_mask</cite>.</p>
</dd>
<dt><strong>trainable</strong></dt><dd></dd>
<dt><code class="xref py py-obj docutils literal notranslate"><span class="pre">trainable_variables</span></code></dt><dd><p>Sequence of trainable variables owned by this module and its submodules.</p>
</dd>
<dt><code class="xref py py-obj docutils literal notranslate"><span class="pre">trainable_weights</span></code></dt><dd><p>List of all trainable weights tracked by this layer.</p>
</dd>
<dt><strong>updates</strong></dt><dd></dd>
<dt><code class="xref py py-obj docutils literal notranslate"><span class="pre">variable_dtype</span></code></dt><dd><p>Alias of <cite>Layer.dtype</cite>, the dtype of the weights.</p>
</dd>
<dt><code class="xref py py-obj docutils literal notranslate"><span class="pre">variables</span></code></dt><dd><p>Returns the list of all layer variables/weights.</p>
</dd>
<dt><code class="xref py py-obj docutils literal notranslate"><span class="pre">weights</span></code></dt><dd><p>Returns the list of all layer variables/weights.</p>
</dd>
</dl>
</dd>
</dl>
<p class="rubric">Methods</p>
<table class="longtable table autosummary">
<colgroup>
<col style="width: 10%" />
<col style="width: 90%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">__call__</span></code>(*args, **kwargs)</p></td>
<td><p>Wraps <cite>call</cite>, applying pre- and post-processing steps.</p></td>
</tr>
<tr class="row-even"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">add_loss</span></code>(losses, **kwargs)</p></td>
<td><p>Add loss tensor(s), potentially dependent on layer inputs.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">add_metric</span></code>(value[, name])</p></td>
<td><p>Adds metric tensor to the layer.</p></td>
</tr>
<tr class="row-even"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">add_update</span></code>(updates[, inputs])</p></td>
<td><p>Add update op(s), potentially dependent on layer inputs.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">add_variable</span></code>(*args, **kwargs)</p></td>
<td><p>Deprecated, do NOT use! Alias for <cite>add_weight</cite>.</p></td>
</tr>
<tr class="row-even"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">add_weight</span></code>([name, shape, dtype, …])</p></td>
<td><p>Adds a new variable to the layer.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">apply</span></code>(inputs, *args, **kwargs)</p></td>
<td><p>Deprecated, do NOT use!</p></td>
</tr>
<tr class="row-even"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">build</span></code>(input_shape)</p></td>
<td><p>Builds the model based on input shapes received.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#deeptrack.models.AutoTrackerBaseModel.call" title="deeptrack.models.AutoTrackerBaseModel.call"><code class="xref py py-obj docutils literal notranslate"><span class="pre">call</span></code></a>(x[, training])</p></td>
<td><p>Calls the model on new inputs.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#deeptrack.models.AutoTrackerBaseModel.compile" title="deeptrack.models.AutoTrackerBaseModel.compile"><code class="xref py py-obj docutils literal notranslate"><span class="pre">compile</span></code></a>(*args, **kwargs)</p></td>
<td><p>Configures the model for training.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">compute_mask</span></code>(inputs[, mask])</p></td>
<td><p>Computes an output mask tensor.</p></td>
</tr>
<tr class="row-even"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">compute_output_shape</span></code>(input_shape)</p></td>
<td><p>Computes the output shape of the layer.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">compute_output_signature</span></code>(input_signature)</p></td>
<td><p>Compute the output tensor signature of the layer based on the inputs.</p></td>
</tr>
<tr class="row-even"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">count_params</span></code>()</p></td>
<td><p>Count the total number of scalars composing the weights.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">evaluate</span></code>([x, y, batch_size, verbose, …])</p></td>
<td><p>Returns the loss value &amp; metrics values for the model in test mode.</p></td>
</tr>
<tr class="row-even"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">evaluate_generator</span></code>(generator[, steps, …])</p></td>
<td><p>Evaluates the model on a data generator.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">fit</span></code>([x, y, batch_size, epochs, verbose, …])</p></td>
<td><p>Trains the model for a fixed number of epochs (iterations on a dataset).</p></td>
</tr>
<tr class="row-even"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">fit_generator</span></code>(generator[, steps_per_epoch, …])</p></td>
<td><p>Fits the model on data yielded batch-by-batch by a Python generator.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#deeptrack.models.AutoTrackerBaseModel.from_config" title="deeptrack.models.AutoTrackerBaseModel.from_config"><code class="xref py py-obj docutils literal notranslate"><span class="pre">from_config</span></code></a>(config)</p></td>
<td><p>Creates a layer from its config.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#deeptrack.models.AutoTrackerBaseModel.get_config" title="deeptrack.models.AutoTrackerBaseModel.get_config"><code class="xref py py-obj docutils literal notranslate"><span class="pre">get_config</span></code></a>()</p></td>
<td><p>Returns the config of the layer.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">get_input_at</span></code>(node_index)</p></td>
<td><p>Retrieves the input tensor(s) of a layer at a given node.</p></td>
</tr>
<tr class="row-even"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">get_input_mask_at</span></code>(node_index)</p></td>
<td><p>Retrieves the input mask tensor(s) of a layer at a given node.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">get_input_shape_at</span></code>(node_index)</p></td>
<td><p>Retrieves the input shape(s) of a layer at a given node.</p></td>
</tr>
<tr class="row-even"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">get_layer</span></code>([name, index])</p></td>
<td><p>Retrieves a layer based on either its name (unique) or index.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">get_losses_for</span></code>(inputs)</p></td>
<td><p>Deprecated, do NOT use!</p></td>
</tr>
<tr class="row-even"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">get_output_at</span></code>(node_index)</p></td>
<td><p>Retrieves the output tensor(s) of a layer at a given node.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">get_output_mask_at</span></code>(node_index)</p></td>
<td><p>Retrieves the output mask tensor(s) of a layer at a given node.</p></td>
</tr>
<tr class="row-even"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">get_output_shape_at</span></code>(node_index)</p></td>
<td><p>Retrieves the output shape(s) of a layer at a given node.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">get_updates_for</span></code>(inputs)</p></td>
<td><p>Deprecated, do NOT use!</p></td>
</tr>
<tr class="row-even"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">get_weights</span></code>()</p></td>
<td><p>Retrieves the weights of the model.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">load_weights</span></code>(filepath[, by_name, …])</p></td>
<td><p>Loads all layer weights, either from a TensorFlow or an HDF5 weight file.</p></td>
</tr>
<tr class="row-even"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">make_predict_function</span></code>()</p></td>
<td><p>Creates a function that executes one step of inference.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">make_test_function</span></code>()</p></td>
<td><p>Creates a function that executes one step of evaluation.</p></td>
</tr>
<tr class="row-even"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">make_train_function</span></code>()</p></td>
<td><p>Creates a function that executes one step of training.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">predict</span></code>(x[, batch_size, verbose, steps, …])</p></td>
<td><p>Generates output predictions for the input samples.</p></td>
</tr>
<tr class="row-even"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">predict_generator</span></code>(generator[, steps, …])</p></td>
<td><p>Generates predictions for the input samples from a data generator.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">predict_on_batch</span></code>(x)</p></td>
<td><p>Returns predictions for a single batch of samples.</p></td>
</tr>
<tr class="row-even"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">predict_step</span></code>(data)</p></td>
<td><p>The logic for one inference step.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">reset_metrics</span></code>()</p></td>
<td><p>Resets the state of all the metrics in the model.</p></td>
</tr>
<tr class="row-even"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">save</span></code>(filepath[, overwrite, …])</p></td>
<td><p>Saves the model to Tensorflow SavedModel or a single HDF5 file.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">save_weights</span></code>(filepath[, overwrite, …])</p></td>
<td><p>Saves all layer weights.</p></td>
</tr>
<tr class="row-even"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">set_weights</span></code>(weights)</p></td>
<td><p>Sets the weights of the layer, from Numpy arrays.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">summary</span></code>([line_length, positions, print_fn])</p></td>
<td><p>Prints a string summary of the network.</p></td>
</tr>
<tr class="row-even"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">test_on_batch</span></code>(x[, y, sample_weight, …])</p></td>
<td><p>Test the model on a single batch of samples.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">test_step</span></code>(data)</p></td>
<td><p>The logic for one evaluation step.</p></td>
</tr>
<tr class="row-even"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">to_json</span></code>(**kwargs)</p></td>
<td><p>Returns a JSON string containing the network configuration.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">to_yaml</span></code>(**kwargs)</p></td>
<td><p>Returns a yaml string containing the network configuration.</p></td>
</tr>
<tr class="row-even"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">train_on_batch</span></code>(x[, y, sample_weight, …])</p></td>
<td><p>Runs a single gradient update on a single batch of data.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#deeptrack.models.AutoTrackerBaseModel.train_step" title="deeptrack.models.AutoTrackerBaseModel.train_step"><code class="xref py py-obj docutils literal notranslate"><span class="pre">train_step</span></code></a>(data)</p></td>
<td><p>The logic for one training step.</p></td>
</tr>
<tr class="row-even"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">with_name_scope</span></code>(method)</p></td>
<td><p>Decorator to automatically enter the module name scope.</p></td>
</tr>
</tbody>
</table>
<table class="table">
<colgroup>
<col style="width: 62%" />
<col style="width: 38%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><strong>global_pool</strong></p></td>
<td></td>
</tr>
<tr class="row-even"><td><p><strong>reset_states</strong></p></td>
<td></td>
</tr>
<tr class="row-odd"><td><p><strong>softmax</strong></p></td>
<td></td>
</tr>
</tbody>
</table>
<dl class="method">
<dt id="deeptrack.models.AutoTrackerBaseModel.call">
<code class="sig-name descname">call</code><span class="sig-paren">(</span><em class="sig-param">x</em>, <em class="sig-param">training=False</em><span class="sig-paren">)</span><a class="headerlink" href="#deeptrack.models.AutoTrackerBaseModel.call" title="Permalink to this definition">¶</a></dt>
<dd><p>Calls the model on new inputs.</p>
<p>In this case <cite>call</cite> just reapplies
all ops in the graph to the new inputs
(e.g. build a new computational graph from the provided inputs).</p>
<dl>
<dt>Arguments:</dt><dd><p>inputs: A tensor or list of tensors.
training: Boolean or boolean scalar tensor, indicating whether to run</p>
<blockquote>
<div><p>the <cite>Network</cite> in training mode or inference mode.</p>
</div></blockquote>
<dl class="simple">
<dt>mask: A mask or list of masks. A mask can be</dt><dd><p>either a tensor or None (no mask).</p>
</dd>
</dl>
</dd>
<dt>Returns:</dt><dd><p>A tensor if there is a single output, or
a list of tensors if there are more than one outputs.</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="deeptrack.models.AutoTrackerBaseModel.compile">
<code class="sig-name descname">compile</code><span class="sig-paren">(</span><em class="sig-param">*args</em>, <em class="sig-param">**kwargs</em><span class="sig-paren">)</span><a class="headerlink" href="#deeptrack.models.AutoTrackerBaseModel.compile" title="Permalink to this definition">¶</a></dt>
<dd><p>Configures the model for training.</p>
<dl>
<dt>Arguments:</dt><dd><dl>
<dt>optimizer: String (name of optimizer) or optimizer instance. See</dt><dd><p><cite>tf.keras.optimizers</cite>.</p>
</dd>
<dt>loss: String (name of objective function), objective function or</dt><dd><p><cite>tf.keras.losses.Loss</cite> instance. See <cite>tf.keras.losses</cite>. An objective
function is any callable with the signature <cite>loss = fn(y_true,
y_pred)</cite>, where y_true = ground truth values with shape =
<cite>[batch_size, d0, .. dN]</cite>, except sparse loss functions such as sparse
categorical crossentropy where shape = <cite>[batch_size, d0, .. dN-1]</cite>.
y_pred = predicted values with shape = <cite>[batch_size, d0, .. dN]</cite>. It
returns a weighted loss float tensor. If a custom <cite>Loss</cite> instance is
used and reduction is set to NONE, return value has the shape
[batch_size, d0, .. dN-1] ie. per-sample or per-timestep loss values;
otherwise, it is a scalar. If the model has multiple outputs, you can
use a different loss on each output by passing a dictionary or a list
of losses. The loss value that will be minimized by the model will
then be the sum of all individual losses.</p>
</dd>
<dt>metrics: List of metrics to be evaluated by the model during training</dt><dd><p>and testing. Each of this can be a string (name of a built-in
function), function or a <cite>tf.keras.metrics.Metric</cite> instance. See
<cite>tf.keras.metrics</cite>. Typically you will use <cite>metrics=[‘accuracy’]</cite>. A
function is any callable with the signature <cite>result = fn(y_true,
y_pred)</cite>. To specify different metrics for different outputs of a
multi-output model, you could also pass a dictionary, such as</p>
<blockquote>
<div><dl class="simple">
<dt><cite>metrics={‘output_a’: ‘accuracy’, ‘output_b’: [‘accuracy’, ‘mse’]}</cite>.</dt><dd><p>You can also pass a list (len = len(outputs)) of lists of metrics
such as <cite>metrics=[[‘accuracy’], [‘accuracy’, ‘mse’]]</cite> or
<cite>metrics=[‘accuracy’, [‘accuracy’, ‘mse’]]</cite>. When you pass the
strings ‘accuracy’ or ‘acc’, we convert this to one of
<cite>tf.keras.metrics.BinaryAccuracy</cite>,
<cite>tf.keras.metrics.CategoricalAccuracy</cite>,
<cite>tf.keras.metrics.SparseCategoricalAccuracy</cite> based on the loss
function used and the model output shape. We do a similar
conversion for the strings ‘crossentropy’ and ‘ce’ as well.</p>
</dd>
</dl>
</div></blockquote>
</dd>
<dt>loss_weights: Optional list or dictionary specifying scalar coefficients</dt><dd><p>(Python floats) to weight the loss contributions of different model
outputs. The loss value that will be minimized by the model will then
be the <em>weighted sum</em> of all individual losses, weighted by the
<cite>loss_weights</cite> coefficients.</p>
<blockquote>
<div><dl class="simple">
<dt>If a list, it is expected to have a 1:1 mapping to the model’s</dt><dd><p>outputs. If a dict, it is expected to map output names (strings)
to scalar coefficients.</p>
</dd>
</dl>
</div></blockquote>
</dd>
<dt>weighted_metrics: List of metrics to be evaluated and weighted by</dt><dd><p>sample_weight or class_weight during training and testing.</p>
</dd>
<dt>run_eagerly: Bool. Defaults to <cite>False</cite>. If <cite>True</cite>, this <cite>Model</cite>’s</dt><dd><p>logic will not be wrapped in a <cite>tf.function</cite>. Recommended to leave
this as <cite>None</cite> unless your <cite>Model</cite> cannot be run inside a
<cite>tf.function</cite>.</p>
</dd>
<dt>steps_per_execution: Int. Defaults to 1. The number of batches to</dt><dd><p>run during each <cite>tf.function</cite> call. Running multiple batches
inside a single <cite>tf.function</cite> call can greatly improve performance
on TPUs or small models with a large Python overhead.
At most, one full epoch will be run each
execution. If a number larger than the size of the epoch is passed,
the execution will be truncated to the size of the epoch.
Note that if <cite>steps_per_execution</cite> is set to <cite>N</cite>,
<cite>Callback.on_batch_begin</cite> and <cite>Callback.on_batch_end</cite> methods
will only be called every <cite>N</cite> batches
(i.e. before/after each <cite>tf.function</cite> execution).</p>
</dd>
</dl>
<p><a href="#id5"><span class="problematic" id="id6">**</span></a>kwargs: Arguments supported for backwards compatibility only.</p>
</dd>
<dt>Raises:</dt><dd><dl class="simple">
<dt>ValueError: In case of invalid arguments for</dt><dd><p><cite>optimizer</cite>, <cite>loss</cite> or <cite>metrics</cite>.</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="deeptrack.models.AutoTrackerBaseModel.from_config">
<em class="property">classmethod </em><code class="sig-name descname">from_config</code><span class="sig-paren">(</span><em class="sig-param">config</em><span class="sig-paren">)</span><a class="headerlink" href="#deeptrack.models.AutoTrackerBaseModel.from_config" title="Permalink to this definition">¶</a></dt>
<dd><p>Creates a layer from its config.</p>
<p>This method is the reverse of <cite>get_config</cite>,
capable of instantiating the same layer from the config
dictionary. It does not handle layer connectivity
(handled by Network), nor weights (handled by <cite>set_weights</cite>).</p>
<dl class="simple">
<dt>Arguments:</dt><dd><dl class="simple">
<dt>config: A Python dictionary, typically the</dt><dd><p>output of get_config.</p>
</dd>
</dl>
</dd>
<dt>Returns:</dt><dd><p>A layer instance.</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="deeptrack.models.AutoTrackerBaseModel.get_config">
<code class="sig-name descname">get_config</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#deeptrack.models.AutoTrackerBaseModel.get_config" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns the config of the layer.</p>
<p>A layer config is a Python dictionary (serializable)
containing the configuration of a layer.
The same layer can be reinstantiated later
(without its trained weights) from this configuration.</p>
<p>The config of a layer does not include connectivity
information, nor the layer class name. These are handled
by <cite>Network</cite> (one layer of abstraction above).</p>
<dl class="simple">
<dt>Returns:</dt><dd><p>Python dictionary.</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="deeptrack.models.AutoTrackerBaseModel.train_step">
<code class="sig-name descname">train_step</code><span class="sig-paren">(</span><em class="sig-param">data</em><span class="sig-paren">)</span><a class="headerlink" href="#deeptrack.models.AutoTrackerBaseModel.train_step" title="Permalink to this definition">¶</a></dt>
<dd><p>The logic for one training step.</p>
<p>This method can be overridden to support custom training logic.
This method is called by <cite>Model.make_train_function</cite>.</p>
<p>This method should contain the mathematical logic for one step of training.
This typically includes the forward pass, loss calculation, backpropagation,
and metric updates.</p>
<p>Configuration details for <em>how</em> this logic is run (e.g. <cite>tf.function</cite> and
<cite>tf.distribute.Strategy</cite> settings), should be left to
<cite>Model.make_train_function</cite>, which can also be overridden.</p>
<dl class="simple">
<dt>Arguments:</dt><dd><p>data: A nested structure of <a href="#id7"><span class="problematic" id="id8">`</span></a>Tensor`s.</p>
</dd>
<dt>Returns:</dt><dd><p>A <cite>dict</cite> containing values that will be passed to
<cite>tf.keras.callbacks.CallbackList.on_train_batch_end</cite>. Typically, the
values of the <cite>Model</cite>’s metrics are returned. Example:
<cite>{‘loss’: 0.2, ‘accuracy’: 0.7}</cite>.</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</div>
</div>
</div>
<div class="section" id="recurrent">
<h2>recurrent<a class="headerlink" href="#recurrent" title="Permalink to this headline">¶</a></h2>
<div class="section" id="id9">
<h3>Module classes<a class="headerlink" href="#id9" title="Permalink to this headline">¶</a></h3>
<div class="section" id="rnn">
<h4>RNN<a class="headerlink" href="#rnn" title="Permalink to this headline">¶</a></h4>
<dl class="class">
<dt id="deeptrack.models.RNN">
<em class="property">class </em><code class="sig-prename descclassname">deeptrack.models.</code><code class="sig-name descname">RNN</code><span class="sig-paren">(</span><em class="sig-param">input_shape=(51</em>, <em class="sig-param">51</em>, <em class="sig-param">1)</em>, <em class="sig-param">conv_layers_dimensions=(16</em>, <em class="sig-param">32</em>, <em class="sig-param">64</em>, <em class="sig-param">128)</em>, <em class="sig-param">dense_layers_dimensions=(32</em>, <em class="sig-param">)</em>, <em class="sig-param">rnn_layers_dimensions=(32</em>, <em class="sig-param">)</em>, <em class="sig-param">return_sequences=False</em>, <em class="sig-param">output_activation=None</em>, <em class="sig-param">number_of_outputs=3</em>, <em class="sig-param">**kwargs</em><span class="sig-paren">)</span><a class="headerlink" href="#deeptrack.models.RNN" title="Permalink to this definition">¶</a></dt>
<dd><p class="rubric">Methods</p>
<table class="longtable table autosummary">
<colgroup>
<col style="width: 10%" />
<col style="width: 90%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">__call__</span></code>(*args, **kwargs)</p></td>
<td><p>Call self as a function.</p></td>
</tr>
<tr class="row-even"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">action</span></code>([replicate_index])</p></td>
<td><p>Creates the image.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#deeptrack.models.RNN.data_generator" title="deeptrack.models.RNN.data_generator"><code class="xref py py-obj docutils literal notranslate"><span class="pre">data_generator</span></code></a>(*args, **kwargs)</p></td>
<td><p>Generator that asynchronously expands the dataset.</p></td>
</tr>
<tr class="row-even"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">export</span></code>(path, minimum_size[, preprocessing, …])</p></td>
<td><p>Export model unto the BioImage Model Zoo format for use with Fiji and ImageJ.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">fit</span></code>([x, y, batch_size, epochs, verbose, …])</p></td>
<td><p>Trains the model for a fixed number of epochs (iterations on a dataset).</p></td>
</tr>
<tr class="row-even"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">plot</span></code>([input_image, resolve_kwargs, interval])</p></td>
<td><p>Visualizes the output of the feature.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">resolve</span></code>([image_list, replicate_index])</p></td>
<td><p>Call self as a function.</p></td>
</tr>
<tr class="row-even"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">sample</span></code>(**kwargs)</p></td>
<td><p>Returns the feature</p></td>
</tr>
</tbody>
</table>
<table class="table">
<colgroup>
<col style="width: 71%" />
<col style="width: 29%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><strong>add_child</strong></p></td>
<td></td>
</tr>
<tr class="row-even"><td><p><strong>add_dependency</strong></p></td>
<td></td>
</tr>
<tr class="row-odd"><td><p><strong>add_feature</strong></p></td>
<td></td>
</tr>
<tr class="row-even"><td><p><strong>add_preprocessing</strong></p></td>
<td></td>
</tr>
<tr class="row-odd"><td><p><strong>bind_arguments</strong></p></td>
<td></td>
</tr>
<tr class="row-even"><td><p><strong>current_value</strong></p></td>
<td></td>
</tr>
<tr class="row-odd"><td><p><strong>get_citations</strong></p></td>
<td></td>
</tr>
<tr class="row-even"><td><p><strong>invalidate</strong></p></td>
<td></td>
</tr>
<tr class="row-odd"><td><p><strong>is_valid</strong></p></td>
<td></td>
</tr>
<tr class="row-even"><td><p><strong>previous</strong></p></td>
<td></td>
</tr>
<tr class="row-odd"><td><p><strong>recurse_children</strong></p></td>
<td></td>
</tr>
<tr class="row-even"><td><p><strong>recurse_dependencies</strong></p></td>
<td></td>
</tr>
<tr class="row-odd"><td><p><strong>seed</strong></p></td>
<td></td>
</tr>
<tr class="row-even"><td><p><strong>set_value</strong></p></td>
<td></td>
</tr>
<tr class="row-odd"><td><p><strong>store</strong></p></td>
<td></td>
</tr>
<tr class="row-even"><td><p><strong>update</strong></p></td>
<td></td>
</tr>
<tr class="row-odd"><td><p><strong>valid_index</strong></p></td>
<td></td>
</tr>
<tr class="row-even"><td><p><strong>validate</strong></p></td>
<td></td>
</tr>
</tbody>
</table>
<dl class="method">
<dt id="deeptrack.models.RNN.data_generator">
<code class="sig-name descname">data_generator</code><span class="sig-paren">(</span><em class="sig-param">*args</em>, <em class="sig-param">**kwargs</em><span class="sig-paren">)</span><a class="headerlink" href="#deeptrack.models.RNN.data_generator" title="Permalink to this definition">¶</a></dt>
<dd><p>Generator that asynchronously expands the dataset.</p>
<p>Generator that aims to speed up the training of networks by striking a
balance between the generalization gained by generating new images
and the speed gained from reusing images. The generator will continuously
create new training data during training, until <cite>max_data_size</cite> is reached,
at which point the oldest data point is replaced.</p>
<p>The generator is expected to be used with the python “with” statement, which
ensures that the generator worker is consumed correctly.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>feature</strong><span class="classifier">Feature</span></dt><dd><p>The feature to resolve images from.</p>
</dd>
<dt><strong>label_function</strong><span class="classifier">Callable[Image or list of Image] -&gt; array_like</span></dt><dd><p>Function that returns the label corresponding to a feature output.</p>
</dd>
<dt><strong>batch_function</strong><span class="classifier">Callable[Image or list of Image] -&gt; array_like, optional</span></dt><dd><p>Function that returns the training data corresponding a feature output.</p>
</dd>
<dt><strong>min_data_size</strong><span class="classifier">int</span></dt><dd><p>Minimum size of the training data before training starts</p>
</dd>
<dt><strong>max_data_set</strong><span class="classifier">int</span></dt><dd><p>Maximum size of the training data before old data is replaced.</p>
</dd>
<dt><strong>batch_size</strong><span class="classifier">int or Callable[int, int] -&gt; int</span></dt><dd><p>Number of images per batch. A function is expected to accept the current epoch
and the size of the training data as input.</p>
</dd>
<dt><strong>shuffle_batch</strong><span class="classifier">bool</span></dt><dd><p>If True, the batches are shuffled before outputting.</p>
</dd>
<dt><strong>feature_kwargs</strong><span class="classifier">dict or list of dicts</span></dt><dd><p>Set of options to pass to the feature when resolving</p>
</dd>
<dt><strong>ndim</strong><span class="classifier">int</span></dt><dd><p>Number of dimensions of each batch (including the batch dimension).</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

</dd></dl>

</div>
<div class="section" id="id10">
<h4>rnn<a class="headerlink" href="#id10" title="Permalink to this headline">¶</a></h4>
<dl class="attribute">
<dt id="deeptrack.models.rnn">
<code class="sig-prename descclassname">deeptrack.models.</code><code class="sig-name descname">rnn</code><a class="headerlink" href="#deeptrack.models.rnn" title="Permalink to this definition">¶</a></dt>
<dd><p>alias of <code class="xref py py-class docutils literal notranslate"><span class="pre">deeptrack.models.recurrent.RNN</span></code></p>
</dd></dl>

</div>
</div>
</div>
<div class="section" id="utils">
<h2>utils<a class="headerlink" href="#utils" title="Permalink to this headline">¶</a></h2>
<div class="section" id="id11">
<h3>Module classes<a class="headerlink" href="#id11" title="Permalink to this headline">¶</a></h3>
<div class="section" id="kerasmodel">
<h4>KerasModel<a class="headerlink" href="#kerasmodel" title="Permalink to this headline">¶</a></h4>
<dl class="class">
<dt id="deeptrack.models.KerasModel">
<em class="property">class </em><code class="sig-prename descclassname">deeptrack.models.</code><code class="sig-name descname">KerasModel</code><span class="sig-paren">(</span><em class="sig-param">model</em>, <em class="sig-param">loss='mae'</em>, <em class="sig-param">optimizer='adam'</em>, <em class="sig-param">metrics=[]</em>, <em class="sig-param">compile=True</em>, <em class="sig-param">add_batch_dimension_on_resolve=True</em>, <em class="sig-param">**kwargs</em><span class="sig-paren">)</span><a class="headerlink" href="#deeptrack.models.KerasModel" title="Permalink to this definition">¶</a></dt>
<dd><p class="rubric">Methods</p>
<table class="longtable table autosummary">
<colgroup>
<col style="width: 10%" />
<col style="width: 90%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">__call__</span></code>(*args, **kwargs)</p></td>
<td><p>Call self as a function.</p></td>
</tr>
<tr class="row-even"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">action</span></code>([replicate_index])</p></td>
<td><p>Creates the image.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#deeptrack.models.KerasModel.data_generator" title="deeptrack.models.KerasModel.data_generator"><code class="xref py py-obj docutils literal notranslate"><span class="pre">data_generator</span></code></a></p></td>
<td><p>alias of <a class="reference internal" href="generators.html#deeptrack.generators.ContinuousGenerator" title="deeptrack.generators.ContinuousGenerator"><code class="xref py py-class docutils literal notranslate"><span class="pre">deeptrack.generators.ContinuousGenerator</span></code></a></p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#deeptrack.models.KerasModel.export" title="deeptrack.models.KerasModel.export"><code class="xref py py-obj docutils literal notranslate"><span class="pre">export</span></code></a>(path, minimum_size[, preprocessing, …])</p></td>
<td><p>Export model unto the BioImage Model Zoo format for use with Fiji and ImageJ.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#deeptrack.models.KerasModel.fit" title="deeptrack.models.KerasModel.fit"><code class="xref py py-obj docutils literal notranslate"><span class="pre">fit</span></code></a>([x, y, batch_size, epochs, verbose, …])</p></td>
<td><p>Trains the model for a fixed number of epochs (iterations on a dataset).</p></td>
</tr>
<tr class="row-even"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">plot</span></code>([input_image, resolve_kwargs, interval])</p></td>
<td><p>Visualizes the output of the feature.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">resolve</span></code>([image_list, replicate_index])</p></td>
<td><p>Call self as a function.</p></td>
</tr>
<tr class="row-even"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">sample</span></code>(**kwargs)</p></td>
<td><p>Returns the feature</p></td>
</tr>
</tbody>
</table>
<table class="table">
<colgroup>
<col style="width: 71%" />
<col style="width: 29%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><strong>add_child</strong></p></td>
<td></td>
</tr>
<tr class="row-even"><td><p><strong>add_dependency</strong></p></td>
<td></td>
</tr>
<tr class="row-odd"><td><p><strong>add_feature</strong></p></td>
<td></td>
</tr>
<tr class="row-even"><td><p><strong>add_preprocessing</strong></p></td>
<td></td>
</tr>
<tr class="row-odd"><td><p><strong>bind_arguments</strong></p></td>
<td></td>
</tr>
<tr class="row-even"><td><p><strong>current_value</strong></p></td>
<td></td>
</tr>
<tr class="row-odd"><td><p><strong>get_citations</strong></p></td>
<td></td>
</tr>
<tr class="row-even"><td><p><strong>invalidate</strong></p></td>
<td></td>
</tr>
<tr class="row-odd"><td><p><strong>is_valid</strong></p></td>
<td></td>
</tr>
<tr class="row-even"><td><p><strong>previous</strong></p></td>
<td></td>
</tr>
<tr class="row-odd"><td><p><strong>recurse_children</strong></p></td>
<td></td>
</tr>
<tr class="row-even"><td><p><strong>recurse_dependencies</strong></p></td>
<td></td>
</tr>
<tr class="row-odd"><td><p><strong>seed</strong></p></td>
<td></td>
</tr>
<tr class="row-even"><td><p><strong>set_value</strong></p></td>
<td></td>
</tr>
<tr class="row-odd"><td><p><strong>store</strong></p></td>
<td></td>
</tr>
<tr class="row-even"><td><p><strong>update</strong></p></td>
<td></td>
</tr>
<tr class="row-odd"><td><p><strong>valid_index</strong></p></td>
<td></td>
</tr>
<tr class="row-even"><td><p><strong>validate</strong></p></td>
<td></td>
</tr>
</tbody>
</table>
<dl class="attribute">
<dt id="deeptrack.models.KerasModel.data_generator">
<code class="sig-name descname">data_generator</code><a class="headerlink" href="#deeptrack.models.KerasModel.data_generator" title="Permalink to this definition">¶</a></dt>
<dd><p>alias of <a class="reference internal" href="generators.html#deeptrack.generators.ContinuousGenerator" title="deeptrack.generators.ContinuousGenerator"><code class="xref py py-class docutils literal notranslate"><span class="pre">deeptrack.generators.ContinuousGenerator</span></code></a></p>
</dd></dl>

<dl class="method">
<dt id="deeptrack.models.KerasModel.export">
<code class="sig-name descname">export</code><span class="sig-paren">(</span><em class="sig-param">path</em>, <em class="sig-param">minimum_size</em>, <em class="sig-param">preprocessing=None</em>, <em class="sig-param">dij_config=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deeptrack.models.KerasModel.export" title="Permalink to this definition">¶</a></dt>
<dd><p>Export model unto the BioImage Model Zoo format for use with Fiji and ImageJ.</p>
<p>Uses pyDeepImageJ by E. Gómez-de-Mariscal, C. García-López-de-Haro, L. Donati, M. Unser,
A. Muñoz-Barrutia and D. Sage for exporting.</p>
<p>DeepImageJ, used for loading the models into ImageJ, is only compatible with
tensorflow==2.2.1. Models using newer features may not load correctly.</p>
<p>Pre-processing of the data should be defined when creating the model using the preprocess
keyword. Post-processing should be left to other imageJ functionality. If this is not
sufficient, see <cite>https://github.com/deepimagej/pydeepimagej</cite> for what to pass to the
preprocessing and postprocessing arguments.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>path</strong><span class="classifier">str</span></dt><dd><p>Path to store exported files.</p>
</dd>
<dt><strong>minimum_size</strong><span class="classifier">int</span></dt><dd><p>For models where the input size is not fixed (e.g. (None, None 1)), the input
is required to be a multiple of this value.</p>
</dd>
<dt><strong>preprocessing</strong><span class="classifier">Feature or Layer</span></dt><dd><p>Additional preprocessing. Will be saved as a part of the network, and as
such need to be compatible with tensorflow tensor operations. Assumed to have the
same input shape as the first layer of the network.</p>
</dd>
<dt><strong>dij_config</strong><span class="classifier">BioImageModelZooConfig, optional</span></dt><dd><p>Configuration used for deployment. See <cite>https://github.com/deepimagej/pydeepimagej</cite> for
list of options. If None, a basic config is created for you.</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="deeptrack.models.KerasModel.fit">
<code class="sig-name descname">fit</code><span class="sig-paren">(</span><em class="sig-param">x=None</em>, <em class="sig-param">y=None</em>, <em class="sig-param">batch_size=None</em>, <em class="sig-param">epochs=1</em>, <em class="sig-param">verbose=1</em>, <em class="sig-param">callbacks=None</em>, <em class="sig-param">validation_split=0.0</em>, <em class="sig-param">validation_data=None</em>, <em class="sig-param">shuffle=True</em>, <em class="sig-param">class_weight=None</em>, <em class="sig-param">sample_weight=None</em>, <em class="sig-param">initial_epoch=0</em>, <em class="sig-param">steps_per_epoch=None</em>, <em class="sig-param">validation_steps=None</em>, <em class="sig-param">validation_batch_size=None</em>, <em class="sig-param">validation_freq=1</em>, <em class="sig-param">max_queue_size=10</em>, <em class="sig-param">workers=1</em>, <em class="sig-param">use_multiprocessing=False</em><span class="sig-paren">)</span><a class="headerlink" href="#deeptrack.models.KerasModel.fit" title="Permalink to this definition">¶</a></dt>
<dd><p>Trains the model for a fixed number of epochs (iterations on a dataset).</p>
<dl>
<dt>Arguments:</dt><dd><dl>
<dt>x: Input data. It could be:</dt><dd><ul class="simple">
<li><p>A Numpy array (or array-like), or a list of arrays
(in case the model has multiple inputs).</p></li>
<li><p>A TensorFlow tensor, or a list of tensors
(in case the model has multiple inputs).</p></li>
<li><p>A dict mapping input names to the corresponding array/tensors,
if the model has named inputs.</p></li>
<li><p>A <cite>tf.data</cite> dataset. Should return a tuple
of either <cite>(inputs, targets)</cite> or
<cite>(inputs, targets, sample_weights)</cite>.</p></li>
<li><p>A generator or <cite>keras.utils.Sequence</cite> returning <cite>(inputs, targets)</cite>
or <cite>(inputs, targets, sample_weights)</cite>.</p></li>
</ul>
<p>A more detailed description of unpacking behavior for iterator types
(Dataset, generator, Sequence) is given below.</p>
</dd>
<dt>y: Target data. Like the input data <cite>x</cite>,</dt><dd><p>it could be either Numpy array(s) or TensorFlow tensor(s).
It should be consistent with <cite>x</cite> (you cannot have Numpy inputs and
tensor targets, or inversely). If <cite>x</cite> is a dataset, generator,
or <cite>keras.utils.Sequence</cite> instance, <cite>y</cite> should
not be specified (since targets will be obtained from <cite>x</cite>).</p>
</dd>
<dt>batch_size: Integer or <cite>None</cite>.</dt><dd><p>Number of samples per gradient update.
If unspecified, <cite>batch_size</cite> will default to 32.
Do not specify the <cite>batch_size</cite> if your data is in the
form of datasets, generators, or <cite>keras.utils.Sequence</cite> instances
(since they generate batches).</p>
</dd>
<dt>epochs: Integer. Number of epochs to train the model.</dt><dd><p>An epoch is an iteration over the entire <cite>x</cite> and <cite>y</cite>
data provided.
Note that in conjunction with <cite>initial_epoch</cite>,
<cite>epochs</cite> is to be understood as “final epoch”.
The model is not trained for a number of iterations
given by <cite>epochs</cite>, but merely until the epoch
of index <cite>epochs</cite> is reached.</p>
</dd>
<dt>verbose: 0, 1, or 2. Verbosity mode.</dt><dd><p>0 = silent, 1 = progress bar, 2 = one line per epoch.
Note that the progress bar is not particularly useful when
logged to a file, so verbose=2 is recommended when not running
interactively (eg, in a production environment).</p>
</dd>
<dt>callbacks: List of <cite>keras.callbacks.Callback</cite> instances.</dt><dd><p>List of callbacks to apply during training.
See <cite>tf.keras.callbacks</cite>. Note <cite>tf.keras.callbacks.ProgbarLogger</cite>
and <cite>tf.keras.callbacks.History</cite> callbacks are created automatically
and need not be passed into <cite>model.fit</cite>.
<cite>tf.keras.callbacks.ProgbarLogger</cite> is created or not based on
<cite>verbose</cite> argument to <cite>model.fit</cite>.</p>
</dd>
<dt>validation_split: Float between 0 and 1.</dt><dd><blockquote>
<div><p>Fraction of the training data to be used as validation data.
The model will set apart this fraction of the training data,
will not train on it, and will evaluate
the loss and any model metrics
on this data at the end of each epoch.
The validation data is selected from the last samples
in the <cite>x</cite> and <cite>y</cite> data provided, before shuffling. This argument is
not supported when <cite>x</cite> is a dataset, generator or</p>
</div></blockquote>
<p><cite>keras.utils.Sequence</cite> instance.</p>
</dd>
<dt>validation_data: Data on which to evaluate</dt><dd><p>the loss and any model metrics at the end of each epoch.
The model will not be trained on this data. Thus, note the fact
that the validation loss of data provided using <cite>validation_split</cite>
or <cite>validation_data</cite> is not affected by regularization layers like
noise and dropout.
<cite>validation_data</cite> will override <cite>validation_split</cite>.
<cite>validation_data</cite> could be:</p>
<blockquote>
<div><ul class="simple">
<li><p>tuple <cite>(x_val, y_val)</cite> of Numpy arrays or tensors</p></li>
<li><p>tuple <cite>(x_val, y_val, val_sample_weights)</cite> of Numpy arrays</p></li>
<li><p>dataset</p></li>
</ul>
</div></blockquote>
<p>For the first two cases, <cite>batch_size</cite> must be provided.
For the last case, <cite>validation_steps</cite> could be provided.
Note that <cite>validation_data</cite> does not support all the data types that
are supported in <cite>x</cite>, eg, dict, generator or <cite>keras.utils.Sequence</cite>.</p>
</dd>
<dt>shuffle: Boolean (whether to shuffle the training data</dt><dd><p>before each epoch) or str (for ‘batch’). This argument is ignored
when <cite>x</cite> is a generator. ‘batch’ is a special option for dealing
with the limitations of HDF5 data; it shuffles in batch-sized
chunks. Has no effect when <cite>steps_per_epoch</cite> is not <cite>None</cite>.</p>
</dd>
<dt>class_weight: Optional dictionary mapping class indices (integers)</dt><dd><p>to a weight (float) value, used for weighting the loss function
(during training only).
This can be useful to tell the model to
“pay more attention” to samples from
an under-represented class.</p>
</dd>
<dt>sample_weight: Optional Numpy array of weights for</dt><dd><blockquote>
<div><p>the training samples, used for weighting the loss function
(during training only). You can either pass a flat (1D)
Numpy array with the same length as the input samples
(1:1 mapping between weights and samples),
or in the case of temporal data,
you can pass a 2D array with shape
<cite>(samples, sequence_length)</cite>,
to apply a different weight to every timestep of every sample. This
argument is not supported when <cite>x</cite> is a dataset, generator, or</p>
</div></blockquote>
<dl class="simple">
<dt><cite>keras.utils.Sequence</cite> instance, instead provide the sample_weights</dt><dd><p>as the third element of <cite>x</cite>.</p>
</dd>
</dl>
</dd>
<dt>initial_epoch: Integer.</dt><dd><p>Epoch at which to start training
(useful for resuming a previous training run).</p>
</dd>
<dt>steps_per_epoch: Integer or <cite>None</cite>.</dt><dd><p>Total number of steps (batches of samples)
before declaring one epoch finished and starting the
next epoch. When training with input tensors such as
TensorFlow data tensors, the default <cite>None</cite> is equal to
the number of samples in your dataset divided by
the batch size, or 1 if that cannot be determined. If x is a
<cite>tf.data</cite> dataset, and ‘steps_per_epoch’
is None, the epoch will run until the input dataset is exhausted.
When passing an infinitely repeating dataset, you must specify the
<cite>steps_per_epoch</cite> argument. This argument is not supported with
array inputs.</p>
</dd>
<dt>validation_steps: Only relevant if <cite>validation_data</cite> is provided and</dt><dd><p>is a <cite>tf.data</cite> dataset. Total number of steps (batches of
samples) to draw before stopping when performing validation
at the end of every epoch. If ‘validation_steps’ is None, validation
will run until the <cite>validation_data</cite> dataset is exhausted. In the
case of an infinitely repeated dataset, it will run into an
infinite loop. If ‘validation_steps’ is specified and only part of
the dataset will be consumed, the evaluation will start from the
beginning of the dataset at each epoch. This ensures that the same
validation samples are used every time.</p>
</dd>
<dt>validation_batch_size: Integer or <cite>None</cite>.</dt><dd><p>Number of samples per validation batch.
If unspecified, will default to <cite>batch_size</cite>.
Do not specify the <cite>validation_batch_size</cite> if your data is in the
form of datasets, generators, or <cite>keras.utils.Sequence</cite> instances
(since they generate batches).</p>
</dd>
<dt>validation_freq: Only relevant if validation data is provided. Integer</dt><dd><p>or <cite>collections_abc.Container</cite> instance (e.g. list, tuple, etc.).
If an integer, specifies how many training epochs to run before a
new validation run is performed, e.g. <cite>validation_freq=2</cite> runs
validation every 2 epochs. If a Container, specifies the epochs on
which to run validation, e.g. <cite>validation_freq=[1, 2, 10]</cite> runs
validation at the end of the 1st, 2nd, and 10th epochs.</p>
</dd>
<dt>max_queue_size: Integer. Used for generator or <cite>keras.utils.Sequence</cite></dt><dd><p>input only. Maximum size for the generator queue.
If unspecified, <cite>max_queue_size</cite> will default to 10.</p>
</dd>
<dt>workers: Integer. Used for generator or <cite>keras.utils.Sequence</cite> input</dt><dd><p>only. Maximum number of processes to spin up
when using process-based threading. If unspecified, <cite>workers</cite>
will default to 1. If 0, will execute the generator on the main
thread.</p>
</dd>
<dt>use_multiprocessing: Boolean. Used for generator or</dt><dd><p><cite>keras.utils.Sequence</cite> input only. If <cite>True</cite>, use process-based
threading. If unspecified, <cite>use_multiprocessing</cite> will default to
<cite>False</cite>. Note that because this implementation relies on
multiprocessing, you should not pass non-picklable arguments to
the generator as they can’t be passed easily to children processes.</p>
</dd>
</dl>
</dd>
<dt>Unpacking behavior for iterator-like inputs:</dt><dd><blockquote>
<div><p>A common pattern is to pass a tf.data.Dataset, generator, or</p>
</div></blockquote>
<p>tf.keras.utils.Sequence to the <cite>x</cite> argument of fit, which will in fact
yield not only features (x) but optionally targets (y) and sample weights.
Keras requires that the output of such iterator-likes be unambiguous. The
iterator should return a tuple of length 1, 2, or 3, where the optional
second and third elements will be used for y and sample_weight
respectively. Any other type provided will be wrapped in a length one
tuple, effectively treating everything as ‘x’. When yielding dicts, they
should still adhere to the top-level tuple structure.
e.g. <cite>({“x0”: x0, “x1”: x1}, y)</cite>. Keras will not attempt to separate
features, targets, and weights from the keys of a single dict.</p>
<blockquote>
<div><p>A notable unsupported data type is the namedtuple. The reason is that</p>
</div></blockquote>
<p>it behaves like both an ordered datatype (tuple) and a mapping
datatype (dict). So given a namedtuple of the form:</p>
<blockquote>
<div><p><cite>namedtuple(“example_tuple”, [“y”, “x”])</cite></p>
</div></blockquote>
<p>it is ambiguous whether to reverse the order of the elements when
interpreting the value. Even worse is a tuple of the form:</p>
<blockquote>
<div><p><cite>namedtuple(“other_tuple”, [“x”, “y”, “z”])</cite></p>
</div></blockquote>
<p>where it is unclear if the tuple was intended to be unpacked into x, y,
and sample_weight or passed through as a single element to <cite>x</cite>. As a
result the data processing code will simply raise a ValueError if it
encounters a namedtuple. (Along with instructions to remedy the issue.)</p>
</dd>
<dt>Returns:</dt><dd><p>A <cite>History</cite> object. Its <cite>History.history</cite> attribute is
a record of training loss values and metrics values
at successive epochs, as well as validation loss values
and validation metrics values (if applicable).</p>
</dd>
<dt>Raises:</dt><dd><p>RuntimeError: 1. If the model was never compiled or,
2. If <cite>model.fit</cite> is  wrapped in <cite>tf.function</cite>.</p>
<dl class="simple">
<dt>ValueError: In case of mismatch between the provided input data</dt><dd><p>and what the model expects or when the input data is empty.</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

</dd></dl>

</div>
<div class="section" id="model">
<h4>Model<a class="headerlink" href="#model" title="Permalink to this headline">¶</a></h4>
</div>
</div>
<div class="section" id="module-functions">
<h3>Module functions<a class="headerlink" href="#module-functions" title="Permalink to this headline">¶</a></h3>
<div class="section" id="loadmodel">
<h4>LoadModel<a class="headerlink" href="#loadmodel" title="Permalink to this headline">¶</a></h4>
</div>
<div class="section" id="as-kerasmodel">
<h4>as_KerasModel<a class="headerlink" href="#as-kerasmodel" title="Permalink to this headline">¶</a></h4>
<dl class="function">
<dt id="deeptrack.models.as_KerasModel">
<code class="sig-prename descclassname">deeptrack.models.</code><code class="sig-name descname">as_KerasModel</code><span class="sig-paren">(</span><em class="sig-param">func</em><span class="sig-paren">)</span><a class="headerlink" href="#deeptrack.models.as_KerasModel" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</div>
<div class="section" id="compile">
<h4>compile<a class="headerlink" href="#compile" title="Permalink to this headline">¶</a></h4>
</div>
<div class="section" id="load-model">
<h4>load_model<a class="headerlink" href="#load-model" title="Permalink to this headline">¶</a></h4>
</div>
<div class="section" id="register-config">
<h4>register_config<a class="headerlink" href="#register-config" title="Permalink to this headline">¶</a></h4>
</div>
<div class="section" id="with-citation">
<h4>with_citation<a class="headerlink" href="#with-citation" title="Permalink to this headline">¶</a></h4>
<dl class="function">
<dt id="deeptrack.models.with_citation">
<code class="sig-prename descclassname">deeptrack.models.</code><code class="sig-name descname">with_citation</code><span class="sig-paren">(</span><em class="sig-param">citation</em><span class="sig-paren">)</span><a class="headerlink" href="#deeptrack.models.with_citation" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</div>
</div>
</div>
</div>


              </div>
              
              
              <div class='prev-next-bottom'>
                
    <a class='left-prev' id="prev-link" href="math.html" title="previous page">math</a>
    <a class='right-next' id="next-link" href="noises.html" title="next page">noises</a>

              </div>
              
          </main>
          

      </div>
    </div>

    
  <script src="_static/js/index.1e043a052b0af929e4d8.js"></script>


    <footer class="footer mt-5 mt-md-0">
  <div class="container">
    <p>
          &copy; Copyright 2020, Benjamin Midtvedt.<br/>
        Created using <a href="http://sphinx-doc.org/">Sphinx</a> 2.2.0.<br/>
    </p>
  </div>
</footer>
  </body>
</html>