{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys\n",
    "sys.path.append(\"../..\") # Adds the module to path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DeepTrack 2.1 - Generators\n",
    "\n",
    "This tutorial introduces and explains generators.\n",
    "\n",
    "### What are generators?\n",
    "\n",
    "Generators are objects designed to help DeepTrack interface with other packages that want to retrieve the data. They achieve this by automatically executing your features and return data in a standardized format, such as in batches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\GU\\.virtualenvs\\AutoTrackingPaper-UvNsjtmo\\lib\\site-packages\\deeptrack\\backend\\_config.py:11: UserWarning: cupy not installed. GPU-accelerated simulations will not be possible\n",
      "  warnings.warn(\n",
      "C:\\Users\\GU\\.virtualenvs\\AutoTrackingPaper-UvNsjtmo\\lib\\site-packages\\deeptrack\\backend\\_config.py:25: UserWarning: cupy not installed, CPU acceleration not enabled\n",
      "  warnings.warn(\"cupy not installed, CPU acceleration not enabled\")\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_34736/3322349681.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mdeeptrack\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mdt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mu\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munits\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.virtualenvs\\AutoTrackingPaper-UvNsjtmo\\lib\\site-packages\\deeptrack\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0munits\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menable_contexts\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"dt\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[0mphysical_devices\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlist_physical_devices\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"GPU\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.virtualenvs\\AutoTrackingPaper-UvNsjtmo\\lib\\site-packages\\tensorflow\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0msys\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0m_sys\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 41\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtools\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmodule_util\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0m_module_util\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     42\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutil\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlazy_loader\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mLazyLoader\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0m_LazyLoader\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.virtualenvs\\AutoTrackingPaper-UvNsjtmo\\lib\\site-packages\\tensorflow\\python\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[1;31m# pylint: disable=wildcard-import,g-bad-import-order,g-import-not-at-top\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 40\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meager\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcontext\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     41\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpywrap_tensorflow\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0m_pywrap_tensorflow\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     42\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.virtualenvs\\AutoTrackingPaper-UvNsjtmo\\lib\\site-packages\\tensorflow\\python\\eager\\context.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprotobuf\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mconfig_pb2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprotobuf\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mrewriter_config_pb2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 35\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpywrap_tfe\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     36\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtf2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclient\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpywrap_tf_session\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.virtualenvs\\AutoTrackingPaper-UvNsjtmo\\lib\\site-packages\\tensorflow\\python\\pywrap_tfe.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[1;31m# pylint: disable=invalid-import-order,g-bad-import-order, wildcard-import, unused-import\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 28\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpywrap_tensorflow\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     29\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_pywrap_tfe\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.virtualenvs\\AutoTrackingPaper-UvNsjtmo\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     62\u001b[0m   \u001b[1;31m# pylint: disable=wildcard-import,g-import-not-at-top,line-too-long,undefined-variable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 64\u001b[1;33m     \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_pywrap_tensorflow_internal\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     65\u001b[0m   \u001b[1;31m# This try catch logic is because there is no bazel equivalent for py_extension.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m   \u001b[1;31m# Externally in opensource we must enable exceptions to load the shared object\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import deeptrack as dt\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "u = dt.units"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Create a data pipeline\n",
    "\n",
    "For demonstration purposes, we'll define a simple data pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\GU\\.virtualenvs\\AutoTrackingPaper-UvNsjtmo\\lib\\site-packages\\deeptrack\\optics.py:220: RuntimeWarning: invalid value encountered in sqrt\n",
      "  * np.sqrt(1 - (NA / refractive_index_medium) ** 2 * RHO),\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "IMAGE_SIZE = 64\n",
    "particle = dt.MieSphere(position=lambda: np.random.uniform(IMAGE_SIZE / 2 - 4, IMAGE_SIZE / 2 + 4, 2))\n",
    "optics = dt.Brightfield(output_region=(0, 0, IMAGE_SIZE, IMAGE_SIZE))\n",
    "image_pipeline = optics(particle)\n",
    "image_pipeline.plot(cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = image_pipeline >> (lambda image: image.get_property(\"position\") - IMAGE_SIZE / 2)\n",
    "data_pipeline = image_pipeline & label "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. The ContinuousGenerator\n",
    "\n",
    "The main generator used is the `ContinuousGenerator`. This will spin up a new thread in the background to continuously create more data asynchronously. This is very useful when training on the gpu, because it maximizes the utilization of both the gpu and the cpu! You create a generator like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = dt.generators.ContinuousGenerator(data_pipeline)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This will create images in batches for you asunchronously until it is filled up. Then it waits for a signal to replace that data with new data! Of course, you'll want to specify these parameters when creating the generator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A generator that will fill up with 128 samples, and output them in batches of 8.\n",
    "generator = dt.generators.ContinuousGenerator(data_pipeline, batch_size=8, max_data_size=512)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to tell the generator to start creating data, we use the with statement:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\GU\\.virtualenvs\\AutoTrackingPaper-UvNsjtmo\\lib\\site-packages\\deeptrack\\optics.py:220: RuntimeWarning: invalid value encountered in sqrt\n",
      "  * np.sqrt(1 - (NA / refractive_index_medium) ** 2 * RHO),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating 136 / 80 samples before starting training\n",
      "Data is being created!\n"
     ]
    }
   ],
   "source": [
    "with generator:\n",
    "    print(\"Data is being created!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, as soon as you exit the `with` statement, you'll stop generating data. You can start it again by entering a new `with`-statement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I have 17 batches ready for you!\n",
      "I still have 17 batches ready for you!\n",
      "Generating 137 / 80 samples before starting training\n",
      "Working....\n",
      "I have 17 batches ready for you!\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "print(f\"I have {len(generator)} batches ready for you!\")\n",
    "time.sleep(0.5)\n",
    "print(f\"I still have {len(generator)} batches ready for you!\")\n",
    "with generator:\n",
    "    print(f\"Working....\")\n",
    "    time.sleep(1)\n",
    "\n",
    "print(f\"I have {len(generator)} batches ready for you!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 min_data_size\n",
    "\n",
    "`min_data_size` describes how many samples the generator needs to create before it can be used. This is very useful for training, because you might not want to start your training untill you have enough data ready to not overfit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I'll create 10 samples before entering the with-statement\n",
    "generator = dt.generators.ContinuousGenerator(data_pipeline, batch_size=8, min_data_size=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 max_epochs_per_sample\n",
    "\n",
    "Per default, during training, the generator will kepp using the same data until it has been replaced. If the pipeline is fast, this is not a problem. The model will likely see new data frequently. However, if the pipeline is slow, it's possible that each sample does not have time to be replaced fully between epochs. If a model is trained too many epochs on the same data, it may overfit. To mitigate this, we can use the `max_epochs_per_sample` option! This will flag how many times a data-point can be used before it has to be replaced!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data here is guaranteed to be fully replaced every two epochs of training\n",
    "generator = dt.generators.ContinuousGenerator(data_pipeline, batch_size=8, max_epochs_per_sample=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 label_function and batch_function\n",
    "\n",
    "The continuous generator assumes you pipeline works as `data, label = pipeline.update()()`. Sometime this is inconvenient. In these cases you can define two functions that converts the output of the pipeline to the desired format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = dt.generators.ContinuousGenerator(image_pipeline, label_function=lambda x: x.get_property(\"position\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Training a model using a generator!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating 134 / 128 samples before starting training\n",
      "Epoch 1/100\n",
      "16/16 [==============================] - 1s 12ms/step - loss: 2.1062\n",
      "Epoch 2/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 2.0088\n",
      "Epoch 3/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 2.0052\n",
      "Epoch 4/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 1.7071\n",
      "Epoch 5/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6733\n",
      "Epoch 6/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.5141\n",
      "Epoch 7/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3613\n",
      "Epoch 8/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.2902\n",
      "Epoch 9/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.2080\n",
      "Epoch 10/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.1987\n",
      "Epoch 11/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.1689\n",
      "Epoch 12/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.1795\n",
      "Epoch 13/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.1533\n",
      "Epoch 14/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.1525\n",
      "Epoch 15/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.1227\n",
      "Epoch 16/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0989\n",
      "Epoch 17/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.1069\n",
      "Epoch 18/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.1097\n",
      "Epoch 19/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.1102\n",
      "Epoch 20/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.1105\n",
      "Epoch 21/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0993\n",
      "Epoch 22/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0992\n",
      "Epoch 23/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0951\n",
      "Epoch 24/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0695\n",
      "Epoch 25/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0937\n",
      "Epoch 26/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0995\n",
      "Epoch 27/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0783\n",
      "Epoch 28/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.1146\n",
      "Epoch 29/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0918\n",
      "Epoch 30/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.1194\n",
      "Epoch 31/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.1401\n",
      "Epoch 32/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.1035\n",
      "Epoch 33/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.1256\n",
      "Epoch 34/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.1069\n",
      "Epoch 35/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0858\n",
      "Epoch 36/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0995\n",
      "Epoch 37/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0716\n",
      "Epoch 38/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0615\n",
      "Epoch 39/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0952\n",
      "Epoch 40/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0787\n",
      "Epoch 41/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0867\n",
      "Epoch 42/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0722\n",
      "Epoch 43/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0963\n",
      "Epoch 44/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0646\n",
      "Epoch 45/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0779\n",
      "Epoch 46/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0828\n",
      "Epoch 47/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0670\n",
      "Epoch 48/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0769\n",
      "Epoch 49/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0823\n",
      "Epoch 50/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0543\n",
      "Epoch 51/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0701\n",
      "Epoch 52/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0832\n",
      "Epoch 53/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0822\n",
      "Epoch 54/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0660\n",
      "Epoch 55/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0818\n",
      "Epoch 56/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0605\n",
      "Epoch 57/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0698\n",
      "Epoch 58/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0589\n",
      "Epoch 59/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0795\n",
      "Epoch 60/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0585\n",
      "Epoch 61/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0637\n",
      "Epoch 62/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0793\n",
      "Epoch 63/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0645\n",
      "Epoch 64/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0741\n",
      "Epoch 65/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0780\n",
      "Epoch 66/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0741\n",
      "Epoch 67/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0734\n",
      "Epoch 68/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0566\n",
      "Epoch 69/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0660\n",
      "Epoch 70/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0750\n",
      "Epoch 71/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0748\n",
      "Epoch 72/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0512\n",
      "Epoch 73/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0492\n",
      "Epoch 74/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0614\n",
      "Epoch 75/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0888\n",
      "Epoch 76/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0934\n",
      "Epoch 77/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0788\n",
      "Epoch 78/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0579\n",
      "Epoch 79/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0845\n",
      "Epoch 80/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.1109\n",
      "Epoch 81/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0795\n",
      "Epoch 82/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0647\n",
      "Epoch 83/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0830\n",
      "Epoch 84/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0763\n",
      "Epoch 85/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0680\n",
      "Epoch 86/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0568\n",
      "Epoch 87/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0742\n",
      "Epoch 88/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0824\n",
      "Epoch 89/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0789\n",
      "Epoch 90/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0815\n",
      "Epoch 91/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0439\n",
      "Epoch 92/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0644\n",
      "Epoch 93/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0769\n",
      "Epoch 94/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0809\n",
      "Epoch 95/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0907\n",
      "Epoch 96/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0654\n",
      "Epoch 97/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0510\n",
      "Epoch 98/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0490\n",
      "Epoch 99/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0809\n",
      "Epoch 100/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0896\n"
     ]
    }
   ],
   "source": [
    "generator = dt.generators.ContinuousGenerator(\n",
    "    data_pipeline, \n",
    "    batch_size=8, \n",
    "    min_data_size=128, \n",
    "    max_data_size=256,\n",
    "    max_epochs_per_sample=2\n",
    ")\n",
    "\n",
    "model = dt.models.Convolutional(input_shape=(IMAGE_SIZE, IMAGE_SIZE, 1), number_of_outputs=2)\n",
    "\n",
    "with generator:\n",
    "    model.fit(generator, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
